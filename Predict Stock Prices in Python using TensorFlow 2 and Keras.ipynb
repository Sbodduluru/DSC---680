{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Tensorflow 2 and some other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "### training parameters\n",
    "\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "\n",
    "# SPDR Gold Shares (GLD)\n",
    "ticker = \"GLD\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Dataset\n",
    "we need to write a function that downloads the dataset from the Internet and preprocess it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    \n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    \n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "Now that we have a proper function to load and prepare the dataset, we need another core function to build our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "\n",
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "Now that we have all the core functions ready, let's train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3420 samples, validate on 855 samples\n",
      "Epoch 1/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0088 - mean_absolute_error: 0.0860- ETA: 3s - loss: 0.0152 - mea - ETA: 0s - loss: 0.0090 - mean_absolute_error: 0.08\n",
      "Epoch 00001: val_loss improved from inf to 0.00075, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 7s 2ms/sample - loss: 0.0087 - mean_absolute_error: 0.0857 - val_loss: 7.4748e-04 - val_mean_absolute_error: 0.0290\n",
      "Epoch 2/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0387- ETA: 4s -\n",
      "Epoch 00002: val_loss improved from 0.00075 to 0.00071, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0013 - mean_absolute_error: 0.0386 - val_loss: 7.1183e-04 - val_mean_absolute_error: 0.0281\n",
      "Epoch 3/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0386\n",
      "Epoch 00003: val_loss did not improve from 0.00071\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0013 - mean_absolute_error: 0.0387 - val_loss: 7.1736e-04 - val_mean_absolute_error: 0.0287\n",
      "Epoch 4/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0391- ETA: 3s - loss: 0.0012 - mean_ab - ETA: 1s - loss: 0.0014 - mean_absolute_error: - ETA: 1s - loss: 0.0014 - mean_absolute_e\n",
      "Epoch 00004: val_loss improved from 0.00071 to 0.00066, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0013 - mean_absolute_error: 0.0390 - val_loss: 6.5734e-04 - val_mean_absolute_error: 0.0269\n",
      "Epoch 5/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0378- ETA: 2s - loss: 0.0013 - mean_absolute_er - ETA: 1s - loss: 0.0013 - mean_absolut\n",
      "Epoch 00005: val_loss improved from 0.00066 to 0.00066, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0013 - mean_absolute_error: 0.0379 - val_loss: 6.5616e-04 - val_mean_absolute_error: 0.0271\n",
      "Epoch 6/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0371\n",
      "Epoch 00006: val_loss did not improve from 0.00066\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0013 - mean_absolute_error: 0.0372 - val_loss: 7.8747e-04 - val_mean_absolute_error: 0.0304\n",
      "Epoch 7/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0388\n",
      "Epoch 00007: val_loss did not improve from 0.00066\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0013 - mean_absolute_error: 0.0388 - val_loss: 7.8775e-04 - val_mean_absolute_error: 0.0304\n",
      "Epoch 8/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0378- ETA: 2s - loss: 0.0014 - \n",
      "Epoch 00008: val_loss did not improve from 0.00066\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0013 - mean_absolute_error: 0.0377 - val_loss: 8.1599e-04 - val_mean_absolute_error: 0.0305\n",
      "Epoch 9/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0374- ETA: 2s - loss: 0.0012 - mean_absolute_err - ETA: 1s - loss: 0.0013 - mean_absolute_er\n",
      "Epoch 00009: val_loss did not improve from 0.00066\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0375 - val_loss: 7.4484e-04 - val_mean_absolute_error: 0.0294\n",
      "Epoch 10/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0373- ETA: 1s - loss: 0.0012 - mean_absolute_err\n",
      "Epoch 00010: val_loss improved from 0.00066 to 0.00063, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0374 - val_loss: 6.2837e-04 - val_mean_absolute_error: 0.0263\n",
      "Epoch 11/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0365\n",
      "Epoch 00011: val_loss did not improve from 0.00063\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0365 - val_loss: 6.3260e-04 - val_mean_absolute_error: 0.0263\n",
      "Epoch 12/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0371\n",
      "Epoch 00012: val_loss improved from 0.00063 to 0.00063, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0372 - val_loss: 6.2771e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 13/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0361- ETA: 1s - loss: 0.0011 - mean_absolute\n",
      "Epoch 00013: val_loss did not improve from 0.00063\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0011 - mean_absolute_error: 0.0360 - val_loss: 9.4134e-04 - val_mean_absolute_error: 0.0331\n",
      "Epoch 14/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0382- ETA: 2s - loss: 0.0013 - mean_\n",
      "Epoch 00014: val_loss did not improve from 0.00063\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0013 - mean_absolute_error: 0.0381 - val_loss: 8.2960e-04 - val_mean_absolute_error: 0.0315\n",
      "Epoch 15/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0366- ETA: 0s - loss: 0.0012 - mean_absolute_error: \n",
      "Epoch 00015: val_loss did not improve from 0.00063\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0366 - val_loss: 7.4845e-04 - val_mean_absolute_error: 0.0296\n",
      "Epoch 16/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0366- ETA: 3s - loss: 0. - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.03\n",
      "Epoch 00016: val_loss improved from 0.00063 to 0.00062, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0366 - val_loss: 6.2039e-04 - val_mean_absolute_error: 0.0261\n",
      "Epoch 17/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0353- ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.03\n",
      "Epoch 00017: val_loss did not improve from 0.00062\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0011 - mean_absolute_error: 0.0353 - val_loss: 7.0391e-04 - val_mean_absolute_error: 0.0286\n",
      "Epoch 18/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0365- ETA: 0s - loss: 0.0012 - mean_absolute_error\n",
      "Epoch 00018: val_loss did not improve from 0.00062\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0365 - val_loss: 8.3324e-04 - val_mean_absolute_error: 0.0309\n",
      "Epoch 19/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0373- ETA\n",
      "Epoch 00019: val_loss improved from 0.00062 to 0.00062, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0372 - val_loss: 6.1656e-04 - val_mean_absolute_error: 0.0260\n",
      "Epoch 20/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0350- ETA: 2s - loss: 0.0011 - \n",
      "Epoch 00020: val_loss did not improve from 0.00062\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0011 - mean_absolute_error: 0.0350 - val_loss: 6.4738e-04 - val_mean_absolute_error: 0.0271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0354\n",
      "Epoch 00021: val_loss improved from 0.00062 to 0.00061, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0011 - mean_absolute_error: 0.0354 - val_loss: 6.1168e-04 - val_mean_absolute_error: 0.0258\n",
      "Epoch 22/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0351- ETA: 3s - loss: \n",
      "Epoch 00022: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0011 - mean_absolute_error: 0.0351 - val_loss: 0.0011 - val_mean_absolute_error: 0.0357\n",
      "Epoch 23/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0369\n",
      "Epoch 00023: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0012 - mean_absolute_error: 0.0369 - val_loss: 7.3414e-04 - val_mean_absolute_error: 0.0293\n",
      "Epoch 24/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0349- ETA: 3s - loss: 0.001\n",
      "Epoch 00024: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0011 - mean_absolute_error: 0.0349 - val_loss: 6.6364e-04 - val_mean_absolute_error: 0.0269\n",
      "Epoch 25/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.8073e-04 - mean_absolute_error: 0.0336\n",
      "Epoch 00025: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.7952e-04 - mean_absolute_error: 0.0336 - val_loss: 6.7995e-04 - val_mean_absolute_error: 0.0279\n",
      "Epoch 26/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0345\n",
      "Epoch 00026: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0344 - val_loss: 6.4087e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 27/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0340- ETA: 1s - loss: 0.0011 - mean_absolute_error:  - ETA: 1s - loss: 0.0011 - mean_absolute_e\n",
      "Epoch 00027: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0341 - val_loss: 6.3162e-04 - val_mean_absolute_error: 0.0267\n",
      "Epoch 28/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0352- ETA: 3s - loss: 0.0012 - mea - ETA: 0s - loss: 0.0011 - mean_absolute_error: \n",
      "Epoch 00028: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0011 - mean_absolute_error: 0.0351 - val_loss: 9.5588e-04 - val_mean_absolute_error: 0.0336\n",
      "Epoch 29/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0340\n",
      "Epoch 00029: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0340 - val_loss: 7.0598e-04 - val_mean_absolute_error: 0.0286\n",
      "Epoch 30/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0341- ETA: 3s - loss: 0.00\n",
      "Epoch 00030: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0341 - val_loss: 6.6360e-04 - val_mean_absolute_error: 0.0276\n",
      "Epoch 31/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0339- ETA: 2s - loss: 0.0011 \n",
      "Epoch 00031: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0339 - val_loss: 6.2872e-04 - val_mean_absolute_error: 0.0266\n",
      "Epoch 32/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.2913e-04 - mean_absolute_error: 0.0323- ETA: 3s - loss: 8.8240e-04 - me - ETA: 1s - loss: 9.1962e-04 - mean_absolute_\n",
      "Epoch 00032: val_loss did not improve from 0.00061\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.2910e-04 - mean_absolute_error: 0.0323 - val_loss: 6.9035e-04 - val_mean_absolute_error: 0.0276\n",
      "Epoch 33/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0340- ETA: 3s - loss: 0.0011 - mean_absolute_error: 0 - ETA: 3s - loss: 0.0011 - mean_absolut - ETA: 1s - loss: 0.0011 - mean_absol\n",
      "Epoch 00033: val_loss improved from 0.00061 to 0.00060, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0340 - val_loss: 6.0406e-04 - val_mean_absolute_error: 0.0256\n",
      "Epoch 34/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.7866e-04 - mean_absolute_error: 0.0332- ETA: 1s - loss: 9.5198e-04 - mean_absolute_e - ETA: 0s - loss: 9.7585e-04 - mean_absolute_error: 0.\n",
      "Epoch 00034: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.8070e-04 - mean_absolute_error: 0.0333 - val_loss: 6.2240e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 35/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0342     ETA: 5s - loss: 9.9778e-04 - ETA: 1s - loss: 0.0011 - mean_absolute_error: 0 - ETA: 1s - loss: 0.0011 - mean_absolute_\n",
      "Epoch 00035: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0342 - val_loss: 6.5504e-04 - val_mean_absolute_error: 0.0267\n",
      "Epoch 36/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0333    ETA: 4s - loss: 0.0010 - mean_absolute_e - ETA: 3s - loss: 9.9304e-04 - mean_absolut - ETA: 1s - loss: 9.7157e-04 - mean_absolute_error: 0 - ETA: 1s - loss: 9.9367e-04 - mean_absolute_erro - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.033\n",
      "Epoch 00036: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0333 - val_loss: 8.4163e-04 - val_mean_absolute_error: 0.0310\n",
      "Epoch 37/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.9158e-04 - mean_absolute_error: 0.033 - ETA: 0s - loss: 9.8934e-04 - mean_absolute_error: 0.0335\n",
      "Epoch 00037: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.8663e-04 - mean_absolute_error: 0.0334 - val_loss: 7.2511e-04 - val_mean_absolute_error: 0.0283\n",
      "Epoch 38/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0341\n",
      "Epoch 00038: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0340 - val_loss: 6.2973e-04 - val_mean_absolute_error: 0.0267\n",
      "Epoch 39/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.8506e-04 - mean_absolute_error: 0.0336A: 2s - loss: 0.0010 - me\n",
      "Epoch 00039: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.8264e-04 - mean_absolute_error: 0.0335 - val_loss: 6.1496e-04 - val_mean_absolute_error: 0.0258\n",
      "Epoch 40/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.3361e-04 - mean_absolute_error: 0.0327\n",
      "Epoch 00040: val_loss improved from 0.00060 to 0.00060, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.3110e-04 - mean_absolute_error: 0.0327 - val_loss: 5.9738e-04 - val_mean_absolute_error: 0.0256\n",
      "Epoch 41/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.6300e-04 - mean_absolute_error: 0.0328\n",
      "Epoch 00041: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.6178e-04 - mean_absolute_error: 0.0328 - val_loss: 6.0529e-04 - val_mean_absolute_error: 0.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.0370e-04 - mean_absolute_error: 0.0321- ETA: 4s - loss: 8.5654e-04 - mean_absolute_err - ETA: 3s - loss: 8.28\n",
      "Epoch 00042: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.0285e-04 - mean_absolute_error: 0.0321 - val_loss: 8.8297e-04 - val_mean_absolute_error: 0.0320\n",
      "Epoch 43/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.7595e-04 - mean_absolute_error: 0.0317\n",
      "Epoch 00043: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.7653e-04 - mean_absolute_error: 0.0317 - val_loss: 5.9927e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 44/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.0013e-04 - mean_absolute_error: 0.0321\n",
      "Epoch 00044: val_loss improved from 0.00060 to 0.00060, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.0150e-04 - mean_absolute_error: 0.0321 - val_loss: 5.9660e-04 - val_mean_absolute_error: 0.0256\n",
      "Epoch 45/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.9639e-04 - mean_absolute_error: 0.0319- ETA: 3s - loss: 9.1240e-04 - mean_absolute_e - ETA: 1s - loss: 9.4510e-04 - mean_absol\n",
      "Epoch 00045: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.9973e-04 - mean_absolute_error: 0.0320 - val_loss: 6.3281e-04 - val_mean_absolute_error: 0.0267\n",
      "Epoch 46/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.8641e-04 - mean_absolute_error: 0.0316\n",
      "Epoch 00046: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.8939e-04 - mean_absolute_error: 0.0316 - val_loss: 6.0682e-04 - val_mean_absolute_error: 0.0256\n",
      "Epoch 47/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.6479e-04 - mean_absolute_error: 0.0315- ETA: 2s - loss: 8.7390e-04 - mean_\n",
      "Epoch 00047: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.6207e-04 - mean_absolute_error: 0.0314 - val_loss: 6.1710e-04 - val_mean_absolute_error: 0.0259\n",
      "Epoch 48/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.9135e-04 - mean_absolute_error: 0.0317- ETA: 0s - loss: 8.8326e-04 - mean_absolute_error:\n",
      "Epoch 00048: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.8802e-04 - mean_absolute_error: 0.0316 - val_loss: 6.0950e-04 - val_mean_absolute_error: 0.0257\n",
      "Epoch 49/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.7350e-04 - mean_absolute_error: 0.0314\n",
      "Epoch 00049: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.7671e-04 - mean_absolute_error: 0.0315 - val_loss: 6.1295e-04 - val_mean_absolute_error: 0.0261\n",
      "Epoch 50/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.7578e-04 - mean_absolute_error: 0.0317- ETA: 4s - loss: 9.5029e-04 - mean - ETA: 1s - loss: 9.1866e-04 - mean_absolu\n",
      "Epoch 00050: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.8465e-04 - mean_absolute_error: 0.0318 - val_loss: 7.2936e-04 - val_mean_absolute_error: 0.0286\n",
      "Epoch 51/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.4215e-04 - mean_absolute_error: 0.0309\n",
      "Epoch 00051: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.4265e-04 - mean_absolute_error: 0.0309 - val_loss: 7.1323e-04 - val_mean_absolute_error: 0.0282\n",
      "Epoch 52/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.9371e-04 - mean_absolute_error: 0.0319- ETA: 0s - loss: 8.9655e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00052: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.9558e-04 - mean_absolute_error: 0.0320 - val_loss: 6.0091e-04 - val_mean_absolute_error: 0.0256\n",
      "Epoch 53/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 9.0529e-04 - mean_absolute_error: 0.0322- ETA: 0s - loss: 9.1296e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00053: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 9.0686e-04 - mean_absolute_error: 0.0323 - val_loss: 9.8146e-04 - val_mean_absolute_error: 0.0341\n",
      "Epoch 54/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0340- ETA: 1s - loss: 0.0010 - mean_absolute_e\n",
      "Epoch 00054: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 0.0010 - mean_absolute_error: 0.0340 - val_loss: 6.4829e-04 - val_mean_absolute_error: 0.0267\n",
      "Epoch 55/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.8687e-04 - mean_absolute_error: 0.0322- ETA: 4s - loss: 9.0728e-04 - mean_abs - ETA: 2s - loss: 9.0720e-04 - mean_a\n",
      "Epoch 00055: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.8427e-04 - mean_absolute_error: 0.0321 - val_loss: 6.0844e-04 - val_mean_absolute_error: 0.0262\n",
      "Epoch 56/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.5759e-04 - mean_absolute_error: 0.0313 ETA\n",
      "Epoch 00056: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.5903e-04 - mean_absolute_error: 0.0313 - val_loss: 6.1049e-04 - val_mean_absolute_error: 0.0261\n",
      "Epoch 57/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.4548e-04 - mean_absolute_error: 0.0311\n",
      "Epoch 00057: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.5071e-04 - mean_absolute_error: 0.0312 - val_loss: 6.5035e-04 - val_mean_absolute_error: 0.0266\n",
      "Epoch 58/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.8762e-04 - mean_absolute_error: 0.0315- ETA: 4s - loss\n",
      "Epoch 00058: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.8524e-04 - mean_absolute_error: 0.0314 - val_loss: 6.7450e-04 - val_mean_absolute_error: 0.0272\n",
      "Epoch 59/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.7044e-04 - mean_absolute_error: 0.0314- ETA: 3s - loss: 8.8112e-\n",
      "Epoch 00059: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.7363e-04 - mean_absolute_error: 0.0314 - val_loss: 7.2059e-04 - val_mean_absolute_error: 0.0285\n",
      "Epoch 60/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.5943e-04 - mean_absolute_error: 0.0310- ETA: 1s - loss: 8.8035e-04 - mean_absolute_e\n",
      "Epoch 00060: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.6172e-04 - mean_absolute_error: 0.0311 - val_loss: 5.9816e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 61/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.1735e-04 - mean_absolute_error: 0.0304- ETA: 2s - loss: 8.0185e-04 - mean\n",
      "Epoch 00061: val_loss improved from 0.00060 to 0.00060, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.1997e-04 - mean_absolute_error: 0.0305 - val_loss: 5.9602e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 62/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.1810e-04 - mean_absolute_error: 0.0305- ETA: 4s - l\n",
      "Epoch 00062: val_loss did not improve from 0.00060\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.1732e-04 - mean_absolute_error: 0.0305 - val_loss: 7.2753e-04 - val_mean_absolute_error: 0.0285\n",
      "Epoch 63/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.7098e-04 - mean_absolute_error: 0.0301\n",
      "Epoch 00063: val_loss improved from 0.00060 to 0.00060, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.7053e-04 - mean_absolute_error: 0.0301 - val_loss: 5.9502e-04 - val_mean_absolute_error: 0.0254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.0205e-04 - mean_absolute_error: 0.0305\n",
      "Epoch 00064: val_loss improved from 0.00060 to 0.00059, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.0357e-04 - mean_absolute_error: 0.0305 - val_loss: 5.8703e-04 - val_mean_absolute_error: 0.0253\n",
      "Epoch 65/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.3743e-04 - mean_absolute_error: 0.0308\n",
      "Epoch 00065: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.3599e-04 - mean_absolute_error: 0.0308 - val_loss: 5.9145e-04 - val_mean_absolute_error: 0.0258\n",
      "Epoch 66/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.2960e-04 - mean_absolute_error: 0.0308\n",
      "Epoch 00066: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.2617e-04 - mean_absolute_error: 0.0308 - val_loss: 6.5332e-04 - val_mean_absolute_error: 0.0273\n",
      "Epoch 67/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.0867e-04 - mean_absolute_error: 0.0305\n",
      "Epoch 00067: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.0711e-04 - mean_absolute_error: 0.0304 - val_loss: 7.9053e-04 - val_mean_absolute_error: 0.0305\n",
      "Epoch 68/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.8083e-04 - mean_absolute_error: 0.0316- ETA: 0s - loss: 8.8257e-04 - mean_absolute_error: 0\n",
      "Epoch 00068: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.8348e-04 - mean_absolute_error: 0.0316 - val_loss: 6.6198e-04 - val_mean_absolute_error: 0.0276\n",
      "Epoch 69/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.4649e-04 - mean_absolute_error: 0.0293- ETA: 0s - loss: 7.4234e-04 - mean_absolute_error: 0\n",
      "Epoch 00069: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.4603e-04 - mean_absolute_error: 0.0293 - val_loss: 6.7308e-04 - val_mean_absolute_error: 0.0273\n",
      "Epoch 70/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.9752e-04 - mean_absolute_error: 0.0302\n",
      "Epoch 00070: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.9834e-04 - mean_absolute_error: 0.0303 - val_loss: 5.9525e-04 - val_mean_absolute_error: 0.0256\n",
      "Epoch 71/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.6752e-04 - mean_absolute_error: 0.0294\n",
      "Epoch 00071: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.6986e-04 - mean_absolute_error: 0.0294 - val_loss: 7.1297e-04 - val_mean_absolute_error: 0.0286\n",
      "Epoch 72/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.9799e-04 - mean_absolute_error: 0.0303- ETA: 2s - loss: 8.1005e-04 - me\n",
      "Epoch 00072: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.9570e-04 - mean_absolute_error: 0.0303 - val_loss: 8.3476e-04 - val_mean_absolute_error: 0.0318\n",
      "Epoch 73/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.8928e-04 - mean_absolute_error: 0.0299- ETA: 1s - loss: 7.8257e-04 - mean_absolute_er\n",
      "Epoch 00073: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.8889e-04 - mean_absolute_error: 0.0299 - val_loss: 7.7650e-04 - val_mean_absolute_error: 0.0298\n",
      "Epoch 74/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 8.2945e-04 - mean_absolute_error: 0.0307\n",
      "Epoch 00074: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 8.3071e-04 - mean_absolute_error: 0.0307 - val_loss: 6.7428e-04 - val_mean_absolute_error: 0.0272\n",
      "Epoch 75/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.4251e-04 - mean_absolute_error: 0.0294- ETA: 4s -\n",
      "Epoch 00075: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.4410e-04 - mean_absolute_error: 0.0295 - val_loss: 6.3384e-04 - val_mean_absolute_error: 0.0263\n",
      "Epoch 76/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.3185e-04 - mean_absolute_error: 0.0290\n",
      "Epoch 00076: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.3786e-04 - mean_absolute_error: 0.0291 - val_loss: 6.5630e-04 - val_mean_absolute_error: 0.0268\n",
      "Epoch 77/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.4025e-04 - mean_absolute_error: 0.0295- ETA: 3s - loss: 7.1967e-04 - mean_abs - ETA: 1s - loss: 7.4002e-04 - mean_absolute_error: 0.0 - ETA: 1s - loss: 7.3000e-04 - mean_absolute_error: - ETA: 0s - loss: 7.4546e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00077: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.4121e-04 - mean_absolute_error: 0.0295 - val_loss: 6.0475e-04 - val_mean_absolute_error: 0.0261\n",
      "Epoch 78/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.6657e-04 - mean_absolute_error: 0.0295- ETA: 1s - loss: 7.8137e-04 - mean_absolute\n",
      "Epoch 00078: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.6630e-04 - mean_absolute_error: 0.0296 - val_loss: 6.9593e-04 - val_mean_absolute_error: 0.0278\n",
      "Epoch 79/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.7004e-04 - mean_absolute_error: 0.0302- ETA: 4s - loss: 7.5310e-04 - mean_absolute_err - ETA: 3s - loss: 7.7677e-04 -  - ETA: 0s - loss: 7.7481e-04 - mean_absolute_error: 0.03\n",
      "Epoch 00079: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.7190e-04 - mean_absolute_error: 0.0302 - val_loss: 6.3184e-04 - val_mean_absolute_error: 0.0262\n",
      "Epoch 80/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.3779e-04 - mean_absolute_error: 0.0292\n",
      "Epoch 00080: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.3807e-04 - mean_absolute_error: 0.0292 - val_loss: 6.3953e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 81/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.3256e-04 - mean_absolute_error: 0.0292\n",
      "Epoch 00081: val_loss improved from 0.00059 to 0.00059, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.3190e-04 - mean_absolute_error: 0.0291 - val_loss: 5.8624e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 82/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.7263e-04 - mean_absolute_error: 0.0298\n",
      "Epoch 00082: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.7063e-04 - mean_absolute_error: 0.0297 - val_loss: 5.8758e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 83/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.4580e-04 - mean_absolute_error: 0.0295\n",
      "Epoch 00083: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.4265e-04 - mean_absolute_error: 0.0294 - val_loss: 6.0965e-04 - val_mean_absolute_error: 0.0259\n",
      "Epoch 84/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.4579e-04 - mean_absolute_error: 0.0293- ETA: 4s - \n",
      "Epoch 00084: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.4362e-04 - mean_absolute_error: 0.0293 - val_loss: 5.9760e-04 - val_mean_absolute_error: 0.0258\n",
      "Epoch 85/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.2077e-04 - mean_absolute_error: 0.0290- ETA: 3s - loss: 7.39\n",
      "Epoch 00085: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.2104e-04 - mean_absolute_error: 0.0290 - val_loss: 6.0489e-04 - val_mean_absolute_error: 0.0262\n",
      "Epoch 86/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.1582e-04 - mean_absolute_error: 0.0290\n",
      "Epoch 00086: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.1833e-04 - mean_absolute_error: 0.0291 - val_loss: 6.2121e-04 - val_mean_absolute_error: 0.0266\n",
      "Epoch 87/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.2392e-04 - mean_absolute_error: 0.0290\n",
      "Epoch 00087: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.2648e-04 - mean_absolute_error: 0.0290 - val_loss: 6.1540e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 88/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.0914e-04 - mean_absolute_error: 0.0290- ETA: 1s - loss: 6.9772e-04 - mean_absolute_\n",
      "Epoch 00088: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.0998e-04 - mean_absolute_error: 0.0290 - val_loss: 7.4932e-04 - val_mean_absolute_error: 0.0296\n",
      "Epoch 89/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.8695e-04 - mean_absolute_error: 0.0302\n",
      "Epoch 00089: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.8571e-04 - mean_absolute_error: 0.0302 - val_loss: 5.9852e-04 - val_mean_absolute_error: 0.0259\n",
      "Epoch 90/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.7626e-04 - mean_absolute_error: 0.0300\n",
      "Epoch 00090: val_loss did not improve from 0.00059\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.7511e-04 - mean_absolute_error: 0.0300 - val_loss: 8.0680e-04 - val_mean_absolute_error: 0.0307\n",
      "Epoch 91/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.3225e-04 - mean_absolute_error: 0.0292\n",
      "Epoch 00091: val_loss improved from 0.00059 to 0.00058, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.3395e-04 - mean_absolute_error: 0.0292 - val_loss: 5.7739e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 92/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.2827e-04 - mean_absolute_error: 0.0291\n",
      "Epoch 00092: val_loss did not improve from 0.00058\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.2823e-04 - mean_absolute_error: 0.0292 - val_loss: 7.8813e-04 - val_mean_absolute_error: 0.0305\n",
      "Epoch 93/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.8999e-04 - mean_absolute_error: 0.0285- ETA: 4s - los\n",
      "Epoch 00093: val_loss improved from 0.00058 to 0.00058, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.8964e-04 - mean_absolute_error: 0.0284 - val_loss: 5.7669e-04 - val_mean_absolute_error: 0.0253\n",
      "Epoch 94/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9885e-04 - mean_absolute_error: 0.0286\n",
      "Epoch 00094: val_loss did not improve from 0.00058\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.9889e-04 - mean_absolute_error: 0.0286 - val_loss: 6.1993e-04 - val_mean_absolute_error: 0.0266\n",
      "Epoch 95/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.5970e-04 - mean_absolute_error: 0.0298\n",
      "Epoch 00095: val_loss did not improve from 0.00058\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.6019e-04 - mean_absolute_error: 0.0298 - val_loss: 6.3643e-04 - val_mean_absolute_error: 0.0265\n",
      "Epoch 96/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9179e-04 - mean_absolute_error: 0.0284\n",
      "Epoch 00096: val_loss did not improve from 0.00058\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.8961e-04 - mean_absolute_error: 0.0284 - val_loss: 5.8698e-04 - val_mean_absolute_error: 0.0256\n",
      "Epoch 97/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9366e-04 - mean_absolute_error: 0.0285- ETA: 0s - loss: 6.7431e-04 - mean_absolute_error\n",
      "Epoch 00097: val_loss did not improve from 0.00058\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.9225e-04 - mean_absolute_error: 0.0285 - val_loss: 5.8806e-04 - val_mean_absolute_error: 0.0260\n",
      "Epoch 98/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.0667e-04 - mean_absolute_error: 0.0288\n",
      "Epoch 00098: val_loss did not improve from 0.00058\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.0643e-04 - mean_absolute_error: 0.0288 - val_loss: 6.3473e-04 - val_mean_absolute_error: 0.0273\n",
      "Epoch 99/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.3899e-04 - mean_absolute_error: 0.0295- ETA: 3s - loss: 6.8\n",
      "Epoch 00099: val_loss did not improve from 0.00058\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.3767e-04 - mean_absolute_error: 0.0295 - val_loss: 5.8566e-04 - val_mean_absolute_error: 0.0254\n",
      "Epoch 100/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.8113e-04 - mean_absolute_error: 0.0280\n",
      "Epoch 00100: val_loss improved from 0.00058 to 0.00058, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7969e-04 - mean_absolute_error: 0.0280 - val_loss: 5.7588e-04 - val_mean_absolute_error: 0.0254\n",
      "Epoch 101/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.0191e-04 - mean_absolute_error: 0.0287\n",
      "Epoch 00101: val_loss did not improve from 0.00058\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.0392e-04 - mean_absolute_error: 0.0287 - val_loss: 8.1760e-04 - val_mean_absolute_error: 0.0314\n",
      "Epoch 102/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.1133e-04 - mean_absolute_error: 0.0289\n",
      "Epoch 00102: val_loss improved from 0.00058 to 0.00056, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.1000e-04 - mean_absolute_error: 0.0289 - val_loss: 5.6145e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 103/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6531e-04 - mean_absolute_error: 0.0280\n",
      "Epoch 00103: val_loss did not improve from 0.00056\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6788e-04 - mean_absolute_error: 0.0280 - val_loss: 5.8918e-04 - val_mean_absolute_error: 0.0260\n",
      "Epoch 104/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9357e-04 - mean_absolute_error: 0.0285\n",
      "Epoch 00104: val_loss did not improve from 0.00056\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.9353e-04 - mean_absolute_error: 0.0285 - val_loss: 5.6655e-04 - val_mean_absolute_error: 0.0252\n",
      "Epoch 105/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9945e-04 - mean_absolute_error: 0.0285\n",
      "Epoch 00105: val_loss did not improve from 0.00056\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.9708e-04 - mean_absolute_error: 0.0284 - val_loss: 6.1311e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 106/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.4237e-04 - mean_absolute_error: 0.0294\n",
      "Epoch 00106: val_loss improved from 0.00056 to 0.00056, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.4391e-04 - mean_absolute_error: 0.0294 - val_loss: 5.5984e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 107/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6619e-04 - mean_absolute_error: 0.0280\n",
      "Epoch 00107: val_loss did not improve from 0.00056\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6712e-04 - mean_absolute_error: 0.0280 - val_loss: 5.8906e-04 - val_mean_absolute_error: 0.0259\n",
      "Epoch 108/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6186e-04 - mean_absolute_error: 0.0278\n",
      "Epoch 00108: val_loss did not improve from 0.00056\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6298e-04 - mean_absolute_error: 0.0278 - val_loss: 5.7411e-04 - val_mean_absolute_error: 0.0253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6506e-04 - mean_absolute_error: 0.0277\n",
      "Epoch 00109: val_loss did not improve from 0.00056\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6350e-04 - mean_absolute_error: 0.0277 - val_loss: 6.3735e-04 - val_mean_absolute_error: 0.0270\n",
      "Epoch 110/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7660e-04 - mean_absolute_error: 0.0280- ETA: 1s - loss: 6.5985e-04 - mean_absolute_error: 0. - ETA: 0s - loss: 6.7038e-04 - mean_absolute_error: 0.0 - ETA: 0s - loss: 6.7056e-04 - mean_absolute_error: \n",
      "Epoch 00110: val_loss improved from 0.00056 to 0.00055, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7658e-04 - mean_absolute_error: 0.0280 - val_loss: 5.4811e-04 - val_mean_absolute_error: 0.0246\n",
      "Epoch 111/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.8913e-04 - mean_absolute_error: 0.0285\n",
      "Epoch 00111: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.8996e-04 - mean_absolute_error: 0.0285 - val_loss: 5.8183e-04 - val_mean_absolute_error: 0.0258\n",
      "Epoch 112/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4546e-04 - mean_absolute_error: 0.0275\n",
      "Epoch 00112: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4272e-04 - mean_absolute_error: 0.0275 - val_loss: 7.3004e-04 - val_mean_absolute_error: 0.0293\n",
      "Epoch 113/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.8903e-04 - mean_absolute_error: 0.0281- ETA: 2s - loss: 6.9187e-04 - mean_\n",
      "Epoch 00113: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.8704e-04 - mean_absolute_error: 0.0280 - val_loss: 6.4393e-04 - val_mean_absolute_error: 0.0272\n",
      "Epoch 114/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9841e-04 - mean_absolute_error: 0.0288- ETA: 0s - loss: 6.8311e-04 - mean_absolute_erro\n",
      "Epoch 00114: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.9727e-04 - mean_absolute_error: 0.0287 - val_loss: 6.3361e-04 - val_mean_absolute_error: 0.0269\n",
      "Epoch 115/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9134e-04 - mean_absolute_error: 0.0283\n",
      "Epoch 00115: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.9053e-04 - mean_absolute_error: 0.0283 - val_loss: 5.5817e-04 - val_mean_absolute_error: 0.0250\n",
      "Epoch 116/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5923e-04 - mean_absolute_error: 0.0279- ETA: 3s - loss: 6.51\n",
      "Epoch 00116: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6250e-04 - mean_absolute_error: 0.0280 - val_loss: 5.7265e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 117/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7165e-04 - mean_absolute_error: 0.0281- ETA: 2s - loss: 6.6862e-04 - mean_\n",
      "Epoch 00117: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7678e-04 - mean_absolute_error: 0.0282 - val_loss: 5.7501e-04 - val_mean_absolute_error: 0.0257\n",
      "Epoch 118/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4858e-04 - mean_absolute_error: 0.0278- ETA: 1s - loss: 6.3747e-04 - mean_absolute_er\n",
      "Epoch 00118: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.5218e-04 - mean_absolute_error: 0.0279 - val_loss: 6.1747e-04 - val_mean_absolute_error: 0.0269\n",
      "Epoch 119/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5757e-04 - mean_absolute_error: 0.0278\n",
      "Epoch 00119: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6573e-04 - mean_absolute_error: 0.0279 - val_loss: 5.7717e-04 - val_mean_absolute_error: 0.0258\n",
      "Epoch 120/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.2733e-04 - mean_absolute_error: 0.0294- ETA: 4s - l\n",
      "Epoch 00120: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.2770e-04 - mean_absolute_error: 0.0293 - val_loss: 6.1279e-04 - val_mean_absolute_error: 0.0265\n",
      "Epoch 121/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6500e-04 - mean_absolute_error: 0.0280- ETA: 0s - loss: 6.6614e-04 - mean_absolute_error: 0.028\n",
      "Epoch 00121: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6604e-04 - mean_absolute_error: 0.0280 - val_loss: 5.4967e-04 - val_mean_absolute_error: 0.0247\n",
      "Epoch 122/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7211e-04 - mean_absolute_error: 0.0281\n",
      "Epoch 00122: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7108e-04 - mean_absolute_error: 0.0281 - val_loss: 5.5380e-04 - val_mean_absolute_error: 0.0250\n",
      "Epoch 123/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7019e-04 - mean_absolute_error: 0.0280\n",
      "Epoch 00123: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6972e-04 - mean_absolute_error: 0.0280 - val_loss: 6.6079e-04 - val_mean_absolute_error: 0.0274\n",
      "Epoch 124/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7259e-04 - mean_absolute_error: 0.0281\n",
      "Epoch 00124: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7325e-04 - mean_absolute_error: 0.0281 - val_loss: 5.8443e-04 - val_mean_absolute_error: 0.0260\n",
      "Epoch 125/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6977e-04 - mean_absolute_error: 0.0279- ETA: 3s - loss: 6.8199e-0\n",
      "Epoch 00125: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7007e-04 - mean_absolute_error: 0.0279 - val_loss: 5.8708e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 126/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.3756e-04 - mean_absolute_error: 0.0294- ETA: 4s - loss: 5.91 - ETA: 0s - loss: 7.5267e-04 - mean_absolute_erro\n",
      "Epoch 00126: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.4174e-04 - mean_absolute_error: 0.0294 - val_loss: 6.1487e-04 - val_mean_absolute_error: 0.0268\n",
      "Epoch 127/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5958e-04 - mean_absolute_error: 0.0278\n",
      "Epoch 00127: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6154e-04 - mean_absolute_error: 0.0279 - val_loss: 5.5053e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 128/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.8680e-04 - mean_absolute_error: 0.0284- ETA: 4s - \n",
      "Epoch 00128: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.8617e-04 - mean_absolute_error: 0.0284 - val_loss: 5.9180e-04 - val_mean_absolute_error: 0.0261\n",
      "Epoch 129/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7780e-04 - mean_absolute_error: 0.0282\n",
      "Epoch 00129: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7590e-04 - mean_absolute_error: 0.0281 - val_loss: 6.3658e-04 - val_mean_absolute_error: 0.0275\n",
      "Epoch 130/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4952e-04 - mean_absolute_error: 0.0275\n",
      "Epoch 00130: val_loss did not improve from 0.00055\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.5071e-04 - mean_absolute_error: 0.0275 - val_loss: 5.5380e-04 - val_mean_absolute_error: 0.0250\n",
      "Epoch 131/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5412e-04 - mean_absolute_error: 0.0276- ETA: 3s - loss: 6.7087e-0 - ETA: 0s - loss: 6.5616e-04 - mean_absolute_error:\n",
      "Epoch 00131: val_loss improved from 0.00055 to 0.00053, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.5384e-04 - mean_absolute_error: 0.0276 - val_loss: 5.3427e-04 - val_mean_absolute_error: 0.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7061e-04 - mean_absolute_error: 0.0281- ETA: 1s - loss: 6.7558e-04 - mean_absolu\n",
      "Epoch 00132: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7064e-04 - mean_absolute_error: 0.0282 - val_loss: 5.4881e-04 - val_mean_absolute_error: 0.0247\n",
      "Epoch 133/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5516e-04 - mean_absolute_error: 0.0276\n",
      "Epoch 00133: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.5330e-04 - mean_absolute_error: 0.0276 - val_loss: 5.4197e-04 - val_mean_absolute_error: 0.0245\n",
      "Epoch 134/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7534e-04 - mean_absolute_error: 0.0281- ETA: 2s - loss: 6.9042e-04 - \n",
      "Epoch 00134: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7448e-04 - mean_absolute_error: 0.0281 - val_loss: 5.3826e-04 - val_mean_absolute_error: 0.0244\n",
      "Epoch 135/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4403e-04 - mean_absolute_error: 0.0276\n",
      "Epoch 00135: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4250e-04 - mean_absolute_error: 0.0276 - val_loss: 7.2097e-04 - val_mean_absolute_error: 0.0296\n",
      "Epoch 136/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5686e-04 - mean_absolute_error: 0.0277\n",
      "Epoch 00136: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.5938e-04 - mean_absolute_error: 0.0277 - val_loss: 5.4328e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 137/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 7.0528e-04 - mean_absolute_error: 0.0287- ETA: 3s - loss: 6.\n",
      "Epoch 00137: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 7.0443e-04 - mean_absolute_error: 0.0287 - val_loss: 5.4324e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 138/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4766e-04 - mean_absolute_error: 0.0278\n",
      "Epoch 00138: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4979e-04 - mean_absolute_error: 0.0278 - val_loss: 5.9147e-04 - val_mean_absolute_error: 0.0260\n",
      "Epoch 139/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9942e-04 - mean_absolute_error: 0.0289- ETA: 1s - loss: 7.0296e-04 - mean_absolute\n",
      "Epoch 00139: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.9848e-04 - mean_absolute_error: 0.0289 - val_loss: 5.4199e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 140/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.9267e-04 - mean_absolute_error: 0.0283- ETA: 2s - loss: 6.9363e-04 - m\n",
      "Epoch 00140: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.9139e-04 - mean_absolute_error: 0.0283 - val_loss: 5.4628e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 141/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3704e-04 - mean_absolute_error: 0.0275- ETA: 0s - loss: 6.4530e-04 - mean_absolute_error: 0.\n",
      "Epoch 00141: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3471e-04 - mean_absolute_error: 0.0274 - val_loss: 5.4332e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 142/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2310e-04 - mean_absolute_error: 0.0272- ETA: 1s - loss: 6.1232e-04 - mean_absolu\n",
      "Epoch 00142: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2408e-04 - mean_absolute_error: 0.0272 - val_loss: 5.8974e-04 - val_mean_absolute_error: 0.0262\n",
      "Epoch 143/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5335e-04 - mean_absolute_error: 0.0279\n",
      "Epoch 00143: val_loss improved from 0.00053 to 0.00053, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.5177e-04 - mean_absolute_error: 0.0278 - val_loss: 5.3025e-04 - val_mean_absolute_error: 0.0247\n",
      "Epoch 144/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3582e-04 - mean_absolute_error: 0.0276\n",
      "Epoch 00144: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3869e-04 - mean_absolute_error: 0.0276 - val_loss: 5.9840e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 145/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7706e-04 - mean_absolute_error: 0.0283\n",
      "Epoch 00145: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7884e-04 - mean_absolute_error: 0.0284 - val_loss: 5.4188e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 146/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2606e-04 - mean_absolute_error: 0.0272- ETA: 1s - loss: 6.2442e-04 - mean_absolu\n",
      "Epoch 00146: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2689e-04 - mean_absolute_error: 0.0272 - val_loss: 5.4580e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 147/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3558e-04 - mean_absolute_error: 0.0273- ETA: 5s\n",
      "Epoch 00147: val_loss improved from 0.00053 to 0.00053, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3479e-04 - mean_absolute_error: 0.0273 - val_loss: 5.2696e-04 - val_mean_absolute_error: 0.0245\n",
      "Epoch 148/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6092e-04 - mean_absolute_error: 0.0279\n",
      "Epoch 00148: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6025e-04 - mean_absolute_error: 0.0279 - val_loss: 5.5272e-04 - val_mean_absolute_error: 0.0256\n",
      "Epoch 149/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7125e-04 - mean_absolute_error: 0.0282\n",
      "Epoch 00149: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6995e-04 - mean_absolute_error: 0.0281 - val_loss: 5.5880e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 150/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5303e-04 - mean_absolute_error: 0.0277\n",
      "Epoch 00150: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.5543e-04 - mean_absolute_error: 0.0278 - val_loss: 5.5768e-04 - val_mean_absolute_error: 0.0254\n",
      "Epoch 151/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7886e-04 - mean_absolute_error: 0.0284- ETA: 3s - loss: 6.3505e-04 - mean_absolu - ETA: 1s - loss: 6.5164e-04 - mean_absolute\n",
      "Epoch 00151: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7885e-04 - mean_absolute_error: 0.0284 - val_loss: 7.4757e-04 - val_mean_absolute_error: 0.0293\n",
      "Epoch 152/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.8140e-04 - mean_absolute_error: 0.0283\n",
      "Epoch 00152: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7947e-04 - mean_absolute_error: 0.0282 - val_loss: 5.3265e-04 - val_mean_absolute_error: 0.0244\n",
      "Epoch 153/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3110e-04 - mean_absolute_error: 0.0271\n",
      "Epoch 00153: val_loss did not improve from 0.00053\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3028e-04 - mean_absolute_error: 0.0271 - val_loss: 6.1672e-04 - val_mean_absolute_error: 0.0266\n",
      "Epoch 154/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4737e-04 - mean_absolute_error: 0.0276\n",
      "Epoch 00154: val_loss improved from 0.00053 to 0.00052, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4825e-04 - mean_absolute_error: 0.0276 - val_loss: 5.2362e-04 - val_mean_absolute_error: 0.0243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7056e-04 - mean_absolute_error: 0.0283\n",
      "Epoch 00155: val_loss did not improve from 0.00052\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7861e-04 - mean_absolute_error: 0.0284 - val_loss: 6.1413e-04 - val_mean_absolute_error: 0.0271\n",
      "Epoch 156/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4213e-04 - mean_absolute_error: 0.0277\n",
      "Epoch 00156: val_loss did not improve from 0.00052\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3908e-04 - mean_absolute_error: 0.0276 - val_loss: 5.3302e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 157/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2307e-04 - mean_absolute_error: 0.0273\n",
      "Epoch 00157: val_loss did not improve from 0.00052\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2301e-04 - mean_absolute_error: 0.0274 - val_loss: 5.2446e-04 - val_mean_absolute_error: 0.0245\n",
      "Epoch 158/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.1900e-04 - mean_absolute_error: 0.0271\n",
      "Epoch 00158: val_loss did not improve from 0.00052\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2012e-04 - mean_absolute_error: 0.0271 - val_loss: 5.2584e-04 - val_mean_absolute_error: 0.0242\n",
      "Epoch 159/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2254e-04 - mean_absolute_error: 0.0272- ETA: 1s - loss: 6.1303e-04 - mean_absolute_err\n",
      "Epoch 00159: val_loss did not improve from 0.00052\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2326e-04 - mean_absolute_error: 0.0272 - val_loss: 5.6654e-04 - val_mean_absolute_error: 0.0254\n",
      "Epoch 160/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4276e-04 - mean_absolute_error: 0.0275\n",
      "Epoch 00160: val_loss did not improve from 0.00052\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4043e-04 - mean_absolute_error: 0.0274 - val_loss: 5.3552e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 161/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.7418e-04 - mean_absolute_error: 0.0281- ETA: 1s - loss: 6.4899e-04 - mean_absolut\n",
      "Epoch 00161: val_loss did not improve from 0.00052\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7255e-04 - mean_absolute_error: 0.0280 - val_loss: 5.8431e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 162/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.5817e-04 - mean_absolute_error: 0.0279\n",
      "Epoch 00162: val_loss improved from 0.00052 to 0.00050, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.5792e-04 - mean_absolute_error: 0.0279 - val_loss: 5.0475e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 163/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4712e-04 - mean_absolute_error: 0.0277\n",
      "Epoch 00163: val_loss did not improve from 0.00050\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4483e-04 - mean_absolute_error: 0.0276 - val_loss: 7.4009e-04 - val_mean_absolute_error: 0.0299\n",
      "Epoch 164/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6899e-04 - mean_absolute_error: 0.0284\n",
      "Epoch 00164: val_loss did not improve from 0.00050\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.7037e-04 - mean_absolute_error: 0.0284 - val_loss: 5.7693e-04 - val_mean_absolute_error: 0.0260\n",
      "Epoch 165/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4511e-04 - mean_absolute_error: 0.0278- ETA: 3s - loss: 6.2229e-04\n",
      "Epoch 00165: val_loss did not improve from 0.00050\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4471e-04 - mean_absolute_error: 0.0278 - val_loss: 5.4892e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 166/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3621e-04 - mean_absolute_error: 0.0273- ETA: 1s - loss: 6.4226e-04 - mean_absolute_e\n",
      "Epoch 00166: val_loss did not improve from 0.00050\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3572e-04 - mean_absolute_error: 0.0273 - val_loss: 5.3360e-04 - val_mean_absolute_error: 0.0246\n",
      "Epoch 167/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0942e-04 - mean_absolute_error: 0.0268\n",
      "Epoch 00167: val_loss did not improve from 0.00050\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1420e-04 - mean_absolute_error: 0.0269 - val_loss: 5.2560e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 168/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3691e-04 - mean_absolute_error: 0.0277- ETA: 1s - loss: 6.4810e-04 - mean_absolu\n",
      "Epoch 00168: val_loss improved from 0.00050 to 0.00050, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3629e-04 - mean_absolute_error: 0.0277 - val_loss: 4.9912e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 169/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6569e-04 - mean_absolute_error: 0.0281\n",
      "Epoch 00169: val_loss did not improve from 0.00050\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6390e-04 - mean_absolute_error: 0.0281 - val_loss: 5.2134e-04 - val_mean_absolute_error: 0.0243\n",
      "Epoch 170/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2012e-04 - mean_absolute_error: 0.0270- ETA: 4s - loss: \n",
      "Epoch 00170: val_loss did not improve from 0.00050\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2028e-04 - mean_absolute_error: 0.0270 - val_loss: 5.5330e-04 - val_mean_absolute_error: 0.0254\n",
      "Epoch 171/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3829e-04 - mean_absolute_error: 0.0277- ETA: 1s - loss: 6.1661e-04 - mean_abso\n",
      "Epoch 00171: val_loss did not improve from 0.00050\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4056e-04 - mean_absolute_error: 0.0277 - val_loss: 5.3718e-04 - val_mean_absolute_error: 0.0247\n",
      "Epoch 172/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.1292e-04 - mean_absolute_error: 0.0270\n",
      "Epoch 00172: val_loss improved from 0.00050 to 0.00048, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1396e-04 - mean_absolute_error: 0.0270 - val_loss: 4.8188e-04 - val_mean_absolute_error: 0.0235\n",
      "Epoch 173/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.1213e-04 - mean_absolute_error: 0.0269- ETA: 1s - loss: 5.9962e-04 - mean_absolute_e\n",
      "Epoch 00173: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1290e-04 - mean_absolute_error: 0.0270 - val_loss: 6.1067e-04 - val_mean_absolute_error: 0.0271\n",
      "Epoch 174/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0872e-04 - mean_absolute_error: 0.0270\n",
      "Epoch 00174: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1073e-04 - mean_absolute_error: 0.0271 - val_loss: 5.3590e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 175/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0863e-04 - mean_absolute_error: 0.0270\n",
      "Epoch 00175: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0873e-04 - mean_absolute_error: 0.0270 - val_loss: 5.7677e-04 - val_mean_absolute_error: 0.0260\n",
      "Epoch 176/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2924e-04 - mean_absolute_error: 0.0273\n",
      "Epoch 00176: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2940e-04 - mean_absolute_error: 0.0274 - val_loss: 5.2030e-04 - val_mean_absolute_error: 0.0244\n",
      "Epoch 177/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2725e-04 - mean_absolute_error: 0.0272- ETA: 1s - loss: 6.4442e-04 - mean_absolute_er\n",
      "Epoch 00177: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2885e-04 - mean_absolute_error: 0.0273 - val_loss: 5.0017e-04 - val_mean_absolute_error: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0205e-04 - mean_absolute_error: 0.0267- ETA: 0s - loss: 6.0262e-04 - mean_absolute_error: 0.02\n",
      "Epoch 00178: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0562e-04 - mean_absolute_error: 0.0268 - val_loss: 5.4088e-04 - val_mean_absolute_error: 0.0253\n",
      "Epoch 179/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2829e-04 - mean_absolute_error: 0.0274- ETA: 2s - loss: 6.3591e-04 - m\n",
      "Epoch 00179: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2815e-04 - mean_absolute_error: 0.0274 - val_loss: 5.7008e-04 - val_mean_absolute_error: 0.0258\n",
      "Epoch 180/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.1442e-04 - mean_absolute_error: 0.0270- ETA: 4s - l\n",
      "Epoch 00180: val_loss improved from 0.00048 to 0.00048, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1270e-04 - mean_absolute_error: 0.0269 - val_loss: 4.7919e-04 - val_mean_absolute_error: 0.0235\n",
      "Epoch 181/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0346e-04 - mean_absolute_error: 0.0269\n",
      "Epoch 00181: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0462e-04 - mean_absolute_error: 0.0269 - val_loss: 5.0649e-04 - val_mean_absolute_error: 0.0245\n",
      "Epoch 182/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.1049e-04 - mean_absolute_error: 0.0267\n",
      "Epoch 00182: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1090e-04 - mean_absolute_error: 0.0267 - val_loss: 6.1575e-04 - val_mean_absolute_error: 0.0266\n",
      "Epoch 183/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6601e-04 - mean_absolute_error: 0.0281- ETA: 0s - loss: 6.6847e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00183: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6835e-04 - mean_absolute_error: 0.0281 - val_loss: 5.2847e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 184/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.2129e-04 - mean_absolute_error: 0.0272\n",
      "Epoch 00184: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1909e-04 - mean_absolute_error: 0.0272 - val_loss: 5.3482e-04 - val_mean_absolute_error: 0.0245\n",
      "Epoch 185/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8248e-04 - mean_absolute_error: 0.0264\n",
      "Epoch 00185: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8055e-04 - mean_absolute_error: 0.0263 - val_loss: 4.7959e-04 - val_mean_absolute_error: 0.0235\n",
      "Epoch 186/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.1234e-04 - mean_absolute_error: 0.0270\n",
      "Epoch 00186: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1085e-04 - mean_absolute_error: 0.0269 - val_loss: 5.3011e-04 - val_mean_absolute_error: 0.0244\n",
      "Epoch 187/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8687e-04 - mean_absolute_error: 0.0264\n",
      "Epoch 00187: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8620e-04 - mean_absolute_error: 0.0264 - val_loss: 4.9795e-04 - val_mean_absolute_error: 0.0241\n",
      "Epoch 188/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8840e-04 - mean_absolute_error: 0.0265\n",
      "Epoch 00188: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8677e-04 - mean_absolute_error: 0.0264 - val_loss: 4.8724e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 189/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3273e-04 - mean_absolute_error: 0.0273\n",
      "Epoch 00189: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3040e-04 - mean_absolute_error: 0.0272 - val_loss: 5.0364e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 190/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.6575e-04 - mean_absolute_error: 0.0281\n",
      "Epoch 00190: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.6412e-04 - mean_absolute_error: 0.0280 - val_loss: 5.0798e-04 - val_mean_absolute_error: 0.0241\n",
      "Epoch 191/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9090e-04 - mean_absolute_error: 0.0266\n",
      "Epoch 00191: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9180e-04 - mean_absolute_error: 0.0266 - val_loss: 4.9172e-04 - val_mean_absolute_error: 0.0238\n",
      "Epoch 192/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8098e-04 - mean_absolute_error: 0.0263- ETA: 0s - loss: 5.8421e-04 - mean_absolute_error\n",
      "Epoch 00192: val_loss improved from 0.00048 to 0.00048, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8028e-04 - mean_absolute_error: 0.0263 - val_loss: 4.7564e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 193/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0208e-04 - mean_absolute_error: 0.0268\n",
      "Epoch 00193: val_loss did not improve from 0.00048\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0324e-04 - mean_absolute_error: 0.0268 - val_loss: 4.8157e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 194/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0407e-04 - mean_absolute_error: 0.0268\n",
      "Epoch 00194: val_loss improved from 0.00048 to 0.00047, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0560e-04 - mean_absolute_error: 0.0268 - val_loss: 4.7367e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 195/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.1840e-04 - mean_absolute_error: 0.0271\n",
      "Epoch 00195: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.2040e-04 - mean_absolute_error: 0.0272 - val_loss: 4.9612e-04 - val_mean_absolute_error: 0.0240\n",
      "Epoch 196/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.3090e-04 - mean_absolute_error: 0.0272- ETA: 3s - loss: 6.9812e\n",
      "Epoch 00196: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.3445e-04 - mean_absolute_error: 0.0273 - val_loss: 4.8429e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 197/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.4630e-04 - mean_absolute_error: 0.0277- ETA: 2s - loss: 6.4799e-04 -\n",
      "Epoch 00197: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.4543e-04 - mean_absolute_error: 0.0276 - val_loss: 5.0137e-04 - val_mean_absolute_error: 0.0243\n",
      "Epoch 198/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8273e-04 - mean_absolute_error: 0.0265\n",
      "Epoch 00198: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8108e-04 - mean_absolute_error: 0.0264 - val_loss: 4.7615e-04 - val_mean_absolute_error: 0.0235\n",
      "Epoch 199/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8725e-04 - mean_absolute_error: 0.0264- ETA: 4s - loss: \n",
      "Epoch 00199: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8769e-04 - mean_absolute_error: 0.0264 - val_loss: 5.0506e-04 - val_mean_absolute_error: 0.0243\n",
      "Epoch 200/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.7606e-04 - mean_absolute_error: 0.0260\n",
      "Epoch 00200: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7598e-04 - mean_absolute_error: 0.0260 - val_loss: 4.7518e-04 - val_mean_absolute_error: 0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9085e-04 - mean_absolute_error: 0.0266\n",
      "Epoch 00201: val_loss improved from 0.00047 to 0.00047, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8993e-04 - mean_absolute_error: 0.0266 - val_loss: 4.6812e-04 - val_mean_absolute_error: 0.0235\n",
      "Epoch 202/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9876e-04 - mean_absolute_error: 0.0269\n",
      "Epoch 00202: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9931e-04 - mean_absolute_error: 0.0269 - val_loss: 4.7396e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 203/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0326e-04 - mean_absolute_error: 0.0268\n",
      "Epoch 00203: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0148e-04 - mean_absolute_error: 0.0268 - val_loss: 5.1895e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 204/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0004e-04 - mean_absolute_error: 0.0269- ETA: 2s - loss: 6.0848e-04 - mean_ab - ETA: 0s - loss: 6.0017e-04 - mean_absolute_error: 0.026\n",
      "Epoch 00204: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9929e-04 - mean_absolute_error: 0.0269 - val_loss: 5.0663e-04 - val_mean_absolute_error: 0.0240\n",
      "Epoch 205/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0790e-04 - mean_absolute_error: 0.0267\n",
      "Epoch 00205: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0620e-04 - mean_absolute_error: 0.0266 - val_loss: 4.9835e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 206/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8060e-04 - mean_absolute_error: 0.0263- ETA: 4s -\n",
      "Epoch 00206: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7982e-04 - mean_absolute_error: 0.0263 - val_loss: 5.0680e-04 - val_mean_absolute_error: 0.0249\n",
      "Epoch 207/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0165e-04 - mean_absolute_error: 0.0266- ETA: 2s - loss: 6.0740e-04 - mea\n",
      "Epoch 00207: val_loss did not improve from 0.00047\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0739e-04 - mean_absolute_error: 0.0267 - val_loss: 4.7452e-04 - val_mean_absolute_error: 0.0231\n",
      "Epoch 208/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8356e-04 - mean_absolute_error: 0.0264\n",
      "Epoch 00208: val_loss improved from 0.00047 to 0.00046, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8438e-04 - mean_absolute_error: 0.0264 - val_loss: 4.6377e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 209/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0204e-04 - mean_absolute_error: 0.0268\n",
      "Epoch 00209: val_loss did not improve from 0.00046\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0264e-04 - mean_absolute_error: 0.0268 - val_loss: 5.1908e-04 - val_mean_absolute_error: 0.0245\n",
      "Epoch 210/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8187e-04 - mean_absolute_error: 0.0262\n",
      "Epoch 00210: val_loss did not improve from 0.00046\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8589e-04 - mean_absolute_error: 0.0263 - val_loss: 5.7899e-04 - val_mean_absolute_error: 0.0264\n",
      "Epoch 211/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.7580e-04 - mean_absolute_error: 0.0262\n",
      "Epoch 00211: val_loss did not improve from 0.00046\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7729e-04 - mean_absolute_error: 0.0262 - val_loss: 4.7124e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 212/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.0960e-04 - mean_absolute_error: 0.0267\n",
      "Epoch 00212: val_loss did not improve from 0.00046\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.0870e-04 - mean_absolute_error: 0.0267 - val_loss: 5.0241e-04 - val_mean_absolute_error: 0.0243\n",
      "Epoch 213/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6656e-04 - mean_absolute_error: 0.0259- ETA: 4s - loss: 5.5455e-04 - mean_absolute_error: 0.02 - ETA: 3s - loss: 5.4803e-04 - mean_absolute_error: 0 - ETA: 3s - loss: 5.5664e\n",
      "Epoch 00213: val_loss improved from 0.00046 to 0.00046, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6751e-04 - mean_absolute_error: 0.0259 - val_loss: 4.5647e-04 - val_mean_absolute_error: 0.0231\n",
      "Epoch 214/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.7312e-04 - mean_absolute_error: 0.0262\n",
      "Epoch 00214: val_loss did not improve from 0.00046\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7387e-04 - mean_absolute_error: 0.0262 - val_loss: 4.7941e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 215/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8612e-04 - mean_absolute_error: 0.0265- ETA: 1s - loss: 5.8663e-04 - mean_absolute\n",
      "Epoch 00215: val_loss did not improve from 0.00046\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8649e-04 - mean_absolute_error: 0.0265 - val_loss: 4.7167e-04 - val_mean_absolute_error: 0.0235\n",
      "Epoch 216/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.7216e-04 - mean_absolute_error: 0.0260\n",
      "Epoch 00216: val_loss did not improve from 0.00046\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7106e-04 - mean_absolute_error: 0.0259 - val_loss: 5.1919e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 217/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.7182e-04 - mean_absolute_error: 0.0262\n",
      "Epoch 00217: val_loss did not improve from 0.00046\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7220e-04 - mean_absolute_error: 0.0262 - val_loss: 4.6857e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 218/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.7142e-04 - mean_absolute_error: 0.0261\n",
      "Epoch 00218: val_loss improved from 0.00046 to 0.00045, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7381e-04 - mean_absolute_error: 0.0262 - val_loss: 4.5194e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 219/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.7686e-04 - mean_absolute_error: 0.0262- ETA: 5\n",
      "Epoch 00219: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7576e-04 - mean_absolute_error: 0.0261 - val_loss: 4.5735e-04 - val_mean_absolute_error: 0.0229\n",
      "Epoch 220/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8110e-04 - mean_absolute_error: 0.0263\n",
      "Epoch 00220: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8032e-04 - mean_absolute_error: 0.0263 - val_loss: 5.0327e-04 - val_mean_absolute_error: 0.0242\n",
      "Epoch 221/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9838e-04 - mean_absolute_error: 0.0268- ETA: 3s - loss: 6.4817e-04 - mean_absolute - ETA: 2s - loss: 6.1269e-04 - mean_a\n",
      "Epoch 00221: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9616e-04 - mean_absolute_error: 0.0267 - val_loss: 4.6173e-04 - val_mean_absolute_error: 0.0233\n",
      "Epoch 222/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.8942e-04 - mean_absolute_error: 0.0266- ETA: 0s - loss: 5.7969e-04 - mean_absolute_error:\n",
      "Epoch 00222: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8921e-04 - mean_absolute_error: 0.0266 - val_loss: 4.8947e-04 - val_mean_absolute_error: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6058e-04 - mean_absolute_error: 0.0259\n",
      "Epoch 00223: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6328e-04 - mean_absolute_error: 0.0260 - val_loss: 5.0521e-04 - val_mean_absolute_error: 0.0242\n",
      "Epoch 224/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.7082e-04 - mean_absolute_error: 0.0261\n",
      "Epoch 00224: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6978e-04 - mean_absolute_error: 0.0261 - val_loss: 4.5249e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 225/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9012e-04 - mean_absolute_error: 0.0266\n",
      "Epoch 00225: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.8932e-04 - mean_absolute_error: 0.0266 - val_loss: 4.6371e-04 - val_mean_absolute_error: 0.0231\n",
      "Epoch 226/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 6.1542e-04 - mean_absolute_error: 0.0271\n",
      "Epoch 00226: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 6.1451e-04 - mean_absolute_error: 0.0271 - val_loss: 4.9108e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 227/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6673e-04 - mean_absolute_error: 0.0260\n",
      "Epoch 00227: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6844e-04 - mean_absolute_error: 0.0260 - val_loss: 5.2941e-04 - val_mean_absolute_error: 0.0251\n",
      "Epoch 228/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9411e-04 - mean_absolute_error: 0.0265\n",
      "Epoch 00228: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9312e-04 - mean_absolute_error: 0.0265 - val_loss: 4.6571e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 229/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6808e-04 - mean_absolute_error: 0.0259\n",
      "Epoch 00229: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.7040e-04 - mean_absolute_error: 0.0260 - val_loss: 4.7534e-04 - val_mean_absolute_error: 0.0236\n",
      "Epoch 230/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3666e-04 - mean_absolute_error: 0.0255- ETA: 0s - loss: 5.4655e-04 - mean_absolute_error: \n",
      "Epoch 00230: val_loss improved from 0.00045 to 0.00045, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3847e-04 - mean_absolute_error: 0.0255 - val_loss: 4.4662e-04 - val_mean_absolute_error: 0.0230\n",
      "Epoch 231/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3531e-04 - mean_absolute_error: 0.0251- ETA: 3s - loss: 5.6547e-04\n",
      "Epoch 00231: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3375e-04 - mean_absolute_error: 0.0251 - val_loss: 5.2335e-04 - val_mean_absolute_error: 0.0250\n",
      "Epoch 232/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6369e-04 - mean_absolute_error: 0.0258- ETA: 4s - \n",
      "Epoch 00232: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6260e-04 - mean_absolute_error: 0.0258 - val_loss: 4.8540e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 233/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9003e-04 - mean_absolute_error: 0.0265- ETA: 1s - loss: 5.8248e-04 - mean_absolute_er\n",
      "Epoch 00233: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9084e-04 - mean_absolute_error: 0.0266 - val_loss: 5.4321e-04 - val_mean_absolute_error: 0.0253\n",
      "Epoch 234/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9136e-04 - mean_absolute_error: 0.0266\n",
      "Epoch 00234: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9012e-04 - mean_absolute_error: 0.0265 - val_loss: 4.7481e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 235/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9200e-04 - mean_absolute_error: 0.0267\n",
      "Epoch 00235: val_loss did not improve from 0.00045\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9191e-04 - mean_absolute_error: 0.0268 - val_loss: 4.8205e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 236/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6268e-04 - mean_absolute_error: 0.0259\n",
      "Epoch 00236: val_loss improved from 0.00045 to 0.00044, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6174e-04 - mean_absolute_error: 0.0259 - val_loss: 4.3540e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 237/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5364e-04 - mean_absolute_error: 0.0258\n",
      "Epoch 00237: val_loss did not improve from 0.00044\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5254e-04 - mean_absolute_error: 0.0258 - val_loss: 5.4246e-04 - val_mean_absolute_error: 0.0252\n",
      "Epoch 238/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6163e-04 - mean_absolute_error: 0.0260\n",
      "Epoch 00238: val_loss improved from 0.00044 to 0.00043, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6319e-04 - mean_absolute_error: 0.0260 - val_loss: 4.3110e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 239/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5003e-04 - mean_absolute_error: 0.0256\n",
      "Epoch 00239: val_loss did not improve from 0.00043\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5136e-04 - mean_absolute_error: 0.0256 - val_loss: 4.4350e-04 - val_mean_absolute_error: 0.0230\n",
      "Epoch 240/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4528e-04 - mean_absolute_error: 0.0255- ETA: 4s -\n",
      "Epoch 00240: val_loss did not improve from 0.00043\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4427e-04 - mean_absolute_error: 0.0255 - val_loss: 5.1086e-04 - val_mean_absolute_error: 0.0246\n",
      "Epoch 241/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5045e-04 - mean_absolute_error: 0.0256\n",
      "Epoch 00241: val_loss did not improve from 0.00043\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5347e-04 - mean_absolute_error: 0.0256 - val_loss: 4.7568e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 242/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5917e-04 - mean_absolute_error: 0.0258- ETA: 2s - loss: 5.4497e-04 - mean\n",
      "Epoch 00242: val_loss did not improve from 0.00043\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5643e-04 - mean_absolute_error: 0.0257 - val_loss: 4.9073e-04 - val_mean_absolute_error: 0.0238\n",
      "Epoch 243/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4418e-04 - mean_absolute_error: 0.0257\n",
      "Epoch 00243: val_loss did not improve from 0.00043\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4392e-04 - mean_absolute_error: 0.0256 - val_loss: 4.3132e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 244/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3213e-04 - mean_absolute_error: 0.0251\n",
      "Epoch 00244: val_loss did not improve from 0.00043\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3330e-04 - mean_absolute_error: 0.0252 - val_loss: 4.8937e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 245/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5694e-04 - mean_absolute_error: 0.0256- ETA: 4s - loss: 5.3077e-04 - mean_absolute_error: - ETA: 3s - loss: 5.61\n",
      "Epoch 00245: val_loss did not improve from 0.00043\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5447e-04 - mean_absolute_error: 0.0256 - val_loss: 4.4300e-04 - val_mean_absolute_error: 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4989e-04 - mean_absolute_error: 0.0257\n",
      "Epoch 00246: val_loss improved from 0.00043 to 0.00043, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4989e-04 - mean_absolute_error: 0.0257 - val_loss: 4.2763e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 247/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4888e-04 - mean_absolute_error: 0.0255\n",
      "Epoch 00247: val_loss did not improve from 0.00043\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5096e-04 - mean_absolute_error: 0.0255 - val_loss: 4.3445e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 248/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5316e-04 - mean_absolute_error: 0.0258\n",
      "Epoch 00248: val_loss improved from 0.00043 to 0.00042, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5199e-04 - mean_absolute_error: 0.0258 - val_loss: 4.2052e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 249/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4030e-04 - mean_absolute_error: 0.0256\n",
      "Epoch 00249: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3963e-04 - mean_absolute_error: 0.0255 - val_loss: 6.2477e-04 - val_mean_absolute_error: 0.0276\n",
      "Epoch 250/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.9156e-04 - mean_absolute_error: 0.0266- ETA: 1s - loss: 5.8983e-04 - mean_absolut\n",
      "Epoch 00250: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.9483e-04 - mean_absolute_error: 0.0266 - val_loss: 4.4954e-04 - val_mean_absolute_error: 0.0235\n",
      "Epoch 251/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5667e-04 - mean_absolute_error: 0.0257- ETA: 4s - loss: 5.4296e-04 - mean_absolute_error: 0. - ETA: 3s - loss: 5.34\n",
      "Epoch 00251: val_loss improved from 0.00042 to 0.00042, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5518e-04 - mean_absolute_error: 0.0257 - val_loss: 4.1905e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 252/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.2352e-04 - mean_absolute_error: 0.0251- ETA: 0s - loss: 5.2384e-04 - mean_absolute_error: 0.025\n",
      "Epoch 00252: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.2273e-04 - mean_absolute_error: 0.0251 - val_loss: 4.4257e-04 - val_mean_absolute_error: 0.0227\n",
      "Epoch 253/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3629e-04 - mean_absolute_error: 0.0255\n",
      "Epoch 00253: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3640e-04 - mean_absolute_error: 0.0255 - val_loss: 4.4040e-04 - val_mean_absolute_error: 0.0230\n",
      "Epoch 254/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3714e-04 - mean_absolute_error: 0.0253\n",
      "Epoch 00254: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3636e-04 - mean_absolute_error: 0.0253 - val_loss: 4.7302e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 255/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5378e-04 - mean_absolute_error: 0.0257\n",
      "Epoch 00255: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5227e-04 - mean_absolute_error: 0.0257 - val_loss: 5.7723e-04 - val_mean_absolute_error: 0.0265\n",
      "Epoch 256/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6133e-04 - mean_absolute_error: 0.0258\n",
      "Epoch 00256: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6183e-04 - mean_absolute_error: 0.0258 - val_loss: 4.6460e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 257/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6039e-04 - mean_absolute_error: 0.0258\n",
      "Epoch 00257: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5966e-04 - mean_absolute_error: 0.0258 - val_loss: 4.2869e-04 - val_mean_absolute_error: 0.0223\n",
      "Epoch 258/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5347e-04 - mean_absolute_error: 0.0258\n",
      "Epoch 00258: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5262e-04 - mean_absolute_error: 0.0258 - val_loss: 4.2836e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 259/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4473e-04 - mean_absolute_error: 0.0255\n",
      "Epoch 00259: val_loss did not improve from 0.00042\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4405e-04 - mean_absolute_error: 0.0255 - val_loss: 5.3306e-04 - val_mean_absolute_error: 0.0255\n",
      "Epoch 260/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5088e-04 - mean_absolute_error: 0.0256- ETA: 1s - loss: 5.7113e-04 - mean_absolu\n",
      "Epoch 00260: val_loss improved from 0.00042 to 0.00041, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5045e-04 - mean_absolute_error: 0.0256 - val_loss: 4.1111e-04 - val_mean_absolute_error: 0.0219\n",
      "Epoch 261/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3544e-04 - mean_absolute_error: 0.0254\n",
      "Epoch 00261: val_loss did not improve from 0.00041\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3639e-04 - mean_absolute_error: 0.0254 - val_loss: 4.2675e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 262/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.2283e-04 - mean_absolute_error: 0.0251- ETA: 0s - loss: 5.1007e-04 - mean_absolute_error\n",
      "Epoch 00262: val_loss did not improve from 0.00041\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.2284e-04 - mean_absolute_error: 0.0251 - val_loss: 4.7674e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 263/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3274e-04 - mean_absolute_error: 0.0254\n",
      "Epoch 00263: val_loss did not improve from 0.00041\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3118e-04 - mean_absolute_error: 0.0253 - val_loss: 4.3198e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 264/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4679e-04 - mean_absolute_error: 0.0257\n",
      "Epoch 00264: val_loss did not improve from 0.00041\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4568e-04 - mean_absolute_error: 0.0256 - val_loss: 4.5628e-04 - val_mean_absolute_error: 0.0231\n",
      "Epoch 265/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3827e-04 - mean_absolute_error: 0.0255- ETA: 4s - lo\n",
      "Epoch 00265: val_loss did not improve from 0.00041\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3929e-04 - mean_absolute_error: 0.0255 - val_loss: 5.0667e-04 - val_mean_absolute_error: 0.0250\n",
      "Epoch 266/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3254e-04 - mean_absolute_error: 0.0254- ETA: 3s - loss: 5.4207e-0\n",
      "Epoch 00266: val_loss did not improve from 0.00041\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3152e-04 - mean_absolute_error: 0.0253 - val_loss: 4.3460e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 267/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0733e-04 - mean_absolute_error: 0.0248- ETA: 0s - loss: 5.0451e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00267: val_loss did not improve from 0.00041\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1260e-04 - mean_absolute_error: 0.0249 - val_loss: 4.1802e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 268/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3572e-04 - mean_absolute_error: 0.0253\n",
      "Epoch 00268: val_loss did not improve from 0.00041\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3498e-04 - mean_absolute_error: 0.0253 - val_loss: 4.3475e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 269/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4597e-04 - mean_absolute_error: 0.0254\n",
      "Epoch 00269: val_loss improved from 0.00041 to 0.00040, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4774e-04 - mean_absolute_error: 0.0255 - val_loss: 4.0372e-04 - val_mean_absolute_error: 0.0221\n",
      "Epoch 270/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3266e-04 - mean_absolute_error: 0.0253- ETA: 0s - loss: 5.3071e-04 - mean_absolute_error: 0.025\n",
      "Epoch 00270: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3622e-04 - mean_absolute_error: 0.0254 - val_loss: 4.6118e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 271/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.6068e-04 - mean_absolute_error: 0.0260- ETA: 2s - loss: 5.5952e-04 - mean_ab\n",
      "Epoch 00271: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5998e-04 - mean_absolute_error: 0.0260 - val_loss: 4.4781e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 272/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4866e-04 - mean_absolute_error: 0.0256\n",
      "Epoch 00272: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4680e-04 - mean_absolute_error: 0.0256 - val_loss: 4.2211e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 273/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.2088e-04 - mean_absolute_error: 0.0250- ETA: 3s - loss: 5.4212e-04 \n",
      "Epoch 00273: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.2101e-04 - mean_absolute_error: 0.0250 - val_loss: 4.3208e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 274/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5539e-04 - mean_absolute_error: 0.0257- ETA: 3s - loss: 5.4766\n",
      "Epoch 00274: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.5492e-04 - mean_absolute_error: 0.0257 - val_loss: 4.2152e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 275/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0143e-04 - mean_absolute_error: 0.0246\n",
      "Epoch 00275: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0511e-04 - mean_absolute_error: 0.0247 - val_loss: 4.3988e-04 - val_mean_absolute_error: 0.0234\n",
      "Epoch 276/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.2314e-04 - mean_absolute_error: 0.0249\n",
      "Epoch 00276: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.2227e-04 - mean_absolute_error: 0.0249 - val_loss: 4.7442e-04 - val_mean_absolute_error: 0.0242\n",
      "Epoch 277/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4028e-04 - mean_absolute_error: 0.0254\n",
      "Epoch 00277: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3859e-04 - mean_absolute_error: 0.0253 - val_loss: 4.0665e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 278/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.1468e-04 - mean_absolute_error: 0.0248- ETA: 0s - loss: 5.1744e-04 - mean_absolute_error: 0.0\n",
      "Epoch 00278: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1543e-04 - mean_absolute_error: 0.0248 - val_loss: 4.2254e-04 - val_mean_absolute_error: 0.0223\n",
      "Epoch 279/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3476e-04 - mean_absolute_error: 0.0253\n",
      "Epoch 00279: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3724e-04 - mean_absolute_error: 0.0253 - val_loss: 4.3043e-04 - val_mean_absolute_error: 0.0229\n",
      "Epoch 280/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3815e-04 - mean_absolute_error: 0.0254\n",
      "Epoch 00280: val_loss improved from 0.00040 to 0.00040, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.3711e-04 - mean_absolute_error: 0.0254 - val_loss: 4.0108e-04 - val_mean_absolute_error: 0.0216\n",
      "Epoch 281/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.1089e-04 - mean_absolute_error: 0.0249\n",
      "Epoch 00281: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1185e-04 - mean_absolute_error: 0.0249 - val_loss: 4.0646e-04 - val_mean_absolute_error: 0.0219\n",
      "Epoch 282/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4436e-04 - mean_absolute_error: 0.0254- ETA: 3s - loss: 5.9887e\n",
      "Epoch 00282: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4537e-04 - mean_absolute_error: 0.0255 - val_loss: 4.0870e-04 - val_mean_absolute_error: 0.0223\n",
      "Epoch 283/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.2283e-04 - mean_absolute_error: 0.0251\n",
      "Epoch 00283: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.2208e-04 - mean_absolute_error: 0.0251 - val_loss: 4.4835e-04 - val_mean_absolute_error: 0.0232\n",
      "Epoch 284/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3969e-04 - mean_absolute_error: 0.0253\n",
      "Epoch 00284: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4252e-04 - mean_absolute_error: 0.0254 - val_loss: 5.0178e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 285/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.5929e-04 - mean_absolute_error: 0.0259- ETA: 0s - loss: 5.6030e-04 - mean_absolute_error: 0\n",
      "Epoch 00285: val_loss improved from 0.00040 to 0.00040, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.6142e-04 - mean_absolute_error: 0.0259 - val_loss: 3.9773e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 286/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0148e-04 - mean_absolute_error: 0.0245- ETA: 3s - loss: 5.1190\n",
      "Epoch 00286: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0121e-04 - mean_absolute_error: 0.0245 - val_loss: 4.2076e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 287/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0418e-04 - mean_absolute_error: 0.0247\n",
      "Epoch 00287: val_loss did not improve from 0.00040\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0275e-04 - mean_absolute_error: 0.0246 - val_loss: 4.1741e-04 - val_mean_absolute_error: 0.0221\n",
      "Epoch 288/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4839e-04 - mean_absolute_error: 0.0254\n",
      "Epoch 00288: val_loss improved from 0.00040 to 0.00039, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4768e-04 - mean_absolute_error: 0.0254 - val_loss: 3.9259e-04 - val_mean_absolute_error: 0.0216\n",
      "Epoch 289/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.1306e-04 - mean_absolute_error: 0.0248\n",
      "Epoch 00289: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1088e-04 - mean_absolute_error: 0.0248 - val_loss: 4.0469e-04 - val_mean_absolute_error: 0.0221\n",
      "Epoch 290/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9385e-04 - mean_absolute_error: 0.0243\n",
      "Epoch 00290: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9410e-04 - mean_absolute_error: 0.0243 - val_loss: 4.4953e-04 - val_mean_absolute_error: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.2318e-04 - mean_absolute_error: 0.0251\n",
      "Epoch 00291: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.2246e-04 - mean_absolute_error: 0.0251 - val_loss: 4.1993e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 292/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.1215e-04 - mean_absolute_error: 0.0249- ETA: 1s - loss: 5.1254e-04 - mean_absolute_\n",
      "Epoch 00292: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1455e-04 - mean_absolute_error: 0.0250 - val_loss: 4.1754e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 293/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0456e-04 - mean_absolute_error: 0.0246- ETA: 3s - loss: 4.9191e\n",
      "Epoch 00293: val_loss improved from 0.00039 to 0.00039, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0392e-04 - mean_absolute_error: 0.0246 - val_loss: 3.9073e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 294/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0382e-04 - mean_absolute_error: 0.0247- ETA: 1s - loss: 4.9697e-04 - mean_absolute_\n",
      "Epoch 00294: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0631e-04 - mean_absolute_error: 0.0248 - val_loss: 4.4504e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 295/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.1708e-04 - mean_absolute_error: 0.0249\n",
      "Epoch 00295: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1640e-04 - mean_absolute_error: 0.0248 - val_loss: 4.1443e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 296/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8195e-04 - mean_absolute_error: 0.0240\n",
      "Epoch 00296: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8143e-04 - mean_absolute_error: 0.0240 - val_loss: 4.0968e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 297/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9822e-04 - mean_absolute_error: 0.0246- ETA: 0s - loss: 4.9250e-04 - mean_absolute_error\n",
      "Epoch 00297: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0008e-04 - mean_absolute_error: 0.0247 - val_loss: 3.9705e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 298/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0536e-04 - mean_absolute_error: 0.0248- ETA: 0s - loss: 5.1497e-04 - mean_absolute_error\n",
      "Epoch 00298: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0497e-04 - mean_absolute_error: 0.0248 - val_loss: 4.1731e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 299/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0796e-04 - mean_absolute_error: 0.0247- ETA: 5s \n",
      "Epoch 00299: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0631e-04 - mean_absolute_error: 0.0247 - val_loss: 3.9678e-04 - val_mean_absolute_error: 0.0219\n",
      "Epoch 300/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0706e-04 - mean_absolute_error: 0.0248\n",
      "Epoch 00300: val_loss improved from 0.00039 to 0.00039, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0817e-04 - mean_absolute_error: 0.0249 - val_loss: 3.8616e-04 - val_mean_absolute_error: 0.0217\n",
      "Epoch 301/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9919e-04 - mean_absolute_error: 0.0246\n",
      "Epoch 00301: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9835e-04 - mean_absolute_error: 0.0245 - val_loss: 4.1274e-04 - val_mean_absolute_error: 0.0221\n",
      "Epoch 302/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9422e-04 - mean_absolute_error: 0.0245\n",
      "Epoch 00302: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9461e-04 - mean_absolute_error: 0.0245 - val_loss: 3.9108e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 303/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9557e-04 - mean_absolute_error: 0.0245\n",
      "Epoch 00303: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9660e-04 - mean_absolute_error: 0.0245 - val_loss: 4.2322e-04 - val_mean_absolute_error: 0.0229\n",
      "Epoch 304/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9321e-04 - mean_absolute_error: 0.0244\n",
      "Epoch 00304: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9228e-04 - mean_absolute_error: 0.0244 - val_loss: 4.2388e-04 - val_mean_absolute_error: 0.0227\n",
      "Epoch 305/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9845e-04 - mean_absolute_error: 0.0243\n",
      "Epoch 00305: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9889e-04 - mean_absolute_error: 0.0243 - val_loss: 4.1135e-04 - val_mean_absolute_error: 0.0227\n",
      "Epoch 306/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9332e-04 - mean_absolute_error: 0.024 - ETA: 0s - loss: 4.9253e-04 - mean_absolute_error: 0.0244\n",
      "Epoch 00306: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9265e-04 - mean_absolute_error: 0.0244 - val_loss: 4.1561e-04 - val_mean_absolute_error: 0.0227\n",
      "Epoch 307/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.2662e-04 - mean_absolute_error: 0.0251\n",
      "Epoch 00307: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.2840e-04 - mean_absolute_error: 0.0251 - val_loss: 4.0150e-04 - val_mean_absolute_error: 0.0220\n",
      "Epoch 308/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.1088e-04 - mean_absolute_error: 0.0247\n",
      "Epoch 00308: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1163e-04 - mean_absolute_error: 0.0247 - val_loss: 3.9094e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 309/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0119e-04 - mean_absolute_error: 0.0245\n",
      "Epoch 00309: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0042e-04 - mean_absolute_error: 0.0245 - val_loss: 4.2293e-04 - val_mean_absolute_error: 0.0227\n",
      "Epoch 310/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8228e-04 - mean_absolute_error: 0.0242\n",
      "Epoch 00310: val_loss did not improve from 0.00039\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8101e-04 - mean_absolute_error: 0.0242 - val_loss: 4.5245e-04 - val_mean_absolute_error: 0.0230\n",
      "Epoch 311/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9837e-04 - mean_absolute_error: 0.0246\n",
      "Epoch 00311: val_loss improved from 0.00039 to 0.00037, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9952e-04 - mean_absolute_error: 0.0246 - val_loss: 3.7108e-04 - val_mean_absolute_error: 0.0211\n",
      "Epoch 312/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8972e-04 - mean_absolute_error: 0.0245\n",
      "Epoch 00312: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8892e-04 - mean_absolute_error: 0.0245 - val_loss: 4.1909e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 313/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8992e-04 - mean_absolute_error: 0.0244- ETA: 0s - loss: 4.8733e-04 - mean_absolute_error: 0\n",
      "Epoch 00313: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8984e-04 - mean_absolute_error: 0.0244 - val_loss: 3.8727e-04 - val_mean_absolute_error: 0.0216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.1373e-04 - mean_absolute_error: 0.0248\n",
      "Epoch 00314: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1360e-04 - mean_absolute_error: 0.0249 - val_loss: 3.8114e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 315/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9171e-04 - mean_absolute_error: 0.0244\n",
      "Epoch 00315: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8999e-04 - mean_absolute_error: 0.0243 - val_loss: 4.1769e-04 - val_mean_absolute_error: 0.0221\n",
      "Epoch 316/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9857e-04 - mean_absolute_error: 0.0245\n",
      "Epoch 00316: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9815e-04 - mean_absolute_error: 0.0245 - val_loss: 4.4706e-04 - val_mean_absolute_error: 0.0233\n",
      "Epoch 317/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0646e-04 - mean_absolute_error: 0.0248- ETA: 4s \n",
      "Epoch 00317: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0591e-04 - mean_absolute_error: 0.0248 - val_loss: 3.8618e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 318/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9690e-04 - mean_absolute_error: 0.0245\n",
      "Epoch 00318: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9561e-04 - mean_absolute_error: 0.0244 - val_loss: 3.9264e-04 - val_mean_absolute_error: 0.0216\n",
      "Epoch 319/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9858e-04 - mean_absolute_error: 0.0243\n",
      "Epoch 00319: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9831e-04 - mean_absolute_error: 0.0243 - val_loss: 4.1152e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 320/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9740e-04 - mean_absolute_error: 0.0248\n",
      "Epoch 00320: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9946e-04 - mean_absolute_error: 0.0248 - val_loss: 4.2337e-04 - val_mean_absolute_error: 0.0223\n",
      "Epoch 321/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0663e-04 - mean_absolute_error: 0.0245- ETA: 5s - loss: 5.5658e- - ETA: 1s - loss: 5.1216e-04 - mean_absol\n",
      "Epoch 00321: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0695e-04 - mean_absolute_error: 0.0245 - val_loss: 3.9625e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 322/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8430e-04 - mean_absolute_error: 0.0241\n",
      "Epoch 00322: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8232e-04 - mean_absolute_error: 0.0240 - val_loss: 3.8053e-04 - val_mean_absolute_error: 0.0216\n",
      "Epoch 323/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.1489e-04 - mean_absolute_error: 0.0249- ETA: 0s - loss: 5.2103e-04 - mean_absolute_error: 0.\n",
      "Epoch 00323: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.1286e-04 - mean_absolute_error: 0.0248 - val_loss: 3.7384e-04 - val_mean_absolute_error: 0.0211\n",
      "Epoch 324/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.3031e-04 - mean_absolute_error: 0.0251\n",
      "Epoch 00324: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.2803e-04 - mean_absolute_error: 0.0250 - val_loss: 3.9338e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 325/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7369e-04 - mean_absolute_error: 0.0239- ETA: 4s - loss: 4.9994e-04 - mean_absolute_error: 0. - ETA: 4s - loss: 4.64 - ETA: 0s - loss: 4.7998e-04 - mean_absolute_error: 0\n",
      "Epoch 00325: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7482e-04 - mean_absolute_error: 0.0239 - val_loss: 4.0104e-04 - val_mean_absolute_error: 0.0221\n",
      "Epoch 326/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9666e-04 - mean_absolute_error: 0.0244- ETA: 3s - loss: 5.0570e-04\n",
      "Epoch 00326: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9414e-04 - mean_absolute_error: 0.0244 - val_loss: 3.8183e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 327/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8230e-04 - mean_absolute_error: 0.0241\n",
      "Epoch 00327: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8253e-04 - mean_absolute_error: 0.0241 - val_loss: 4.5422e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 328/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.4985e-04 - mean_absolute_error: 0.0256- ETA: 1s - loss: 5.6549e-04 - mean_absolute_error: - ETA: 0s - loss: 5.5581e-04 - mean_absolute_error: 0.\n",
      "Epoch 00328: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.4827e-04 - mean_absolute_error: 0.0256 - val_loss: 3.8267e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 329/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8047e-04 - mean_absolute_error: 0.0240\n",
      "Epoch 00329: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8080e-04 - mean_absolute_error: 0.0240 - val_loss: 3.8983e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 330/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9870e-04 - mean_absolute_error: 0.0244\n",
      "Epoch 00330: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9725e-04 - mean_absolute_error: 0.0244 - val_loss: 3.7871e-04 - val_mean_absolute_error: 0.0213\n",
      "Epoch 331/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7085e-04 - mean_absolute_error: 0.0238\n",
      "Epoch 00331: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.6976e-04 - mean_absolute_error: 0.0238 - val_loss: 4.0026e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 332/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9524e-04 - mean_absolute_error: 0.0243- ETA: 0s - loss: 4.9455e-04 - mean_absolute_error: 0.024\n",
      "Epoch 00332: val_loss improved from 0.00037 to 0.00037, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9975e-04 - mean_absolute_error: 0.0243 - val_loss: 3.6613e-04 - val_mean_absolute_error: 0.0208\n",
      "Epoch 333/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8761e-04 - mean_absolute_error: 0.0243\n",
      "Epoch 00333: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8850e-04 - mean_absolute_error: 0.0243 - val_loss: 4.1477e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 334/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7949e-04 - mean_absolute_error: 0.0240\n",
      "Epoch 00334: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7860e-04 - mean_absolute_error: 0.0240 - val_loss: 3.8165e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 335/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7384e-04 - mean_absolute_error: 0.0238- ETA: 3s - loss: 4.6575e-04\n",
      "Epoch 00335: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7410e-04 - mean_absolute_error: 0.0238 - val_loss: 3.7548e-04 - val_mean_absolute_error: 0.0215\n",
      "Epoch 336/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8317e-04 - mean_absolute_error: 0.0240\n",
      "Epoch 00336: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8388e-04 - mean_absolute_error: 0.0240 - val_loss: 3.9593e-04 - val_mean_absolute_error: 0.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9313e-04 - mean_absolute_error: 0.0246- ETA: 3s - loss: 4.7871e-04 - mean_abs - ETA: 1s - loss: 4.8779e-04 - mean_absolute_\n",
      "Epoch 00337: val_loss did not improve from 0.00037\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9173e-04 - mean_absolute_error: 0.0245 - val_loss: 4.4367e-04 - val_mean_absolute_error: 0.0223\n",
      "Epoch 338/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9948e-04 - mean_absolute_error: 0.0246\n",
      "Epoch 00338: val_loss improved from 0.00037 to 0.00036, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9986e-04 - mean_absolute_error: 0.0246 - val_loss: 3.6119e-04 - val_mean_absolute_error: 0.0209\n",
      "Epoch 339/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.6721e-04 - mean_absolute_error: 0.0238- ETA: 2s - loss: 4.3420e-04 - m\n",
      "Epoch 00339: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.6502e-04 - mean_absolute_error: 0.0238 - val_loss: 3.9921e-04 - val_mean_absolute_error: 0.0220\n",
      "Epoch 340/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7519e-04 - mean_absolute_error: 0.0239\n",
      "Epoch 00340: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7424e-04 - mean_absolute_error: 0.0239 - val_loss: 4.3811e-04 - val_mean_absolute_error: 0.0233\n",
      "Epoch 341/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8055e-04 - mean_absolute_error: 0.0240\n",
      "Epoch 00341: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8240e-04 - mean_absolute_error: 0.0240 - val_loss: 4.3231e-04 - val_mean_absolute_error: 0.0232\n",
      "Epoch 342/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9919e-04 - mean_absolute_error: 0.0245\n",
      "Epoch 00342: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9784e-04 - mean_absolute_error: 0.0245 - val_loss: 3.8564e-04 - val_mean_absolute_error: 0.0217\n",
      "Epoch 343/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8236e-04 - mean_absolute_error: 0.0242\n",
      "Epoch 00343: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8204e-04 - mean_absolute_error: 0.0242 - val_loss: 3.9235e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 344/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.6387e-04 - mean_absolute_error: 0.0236\n",
      "Epoch 00344: val_loss improved from 0.00036 to 0.00036, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.6516e-04 - mean_absolute_error: 0.0236 - val_loss: 3.5742e-04 - val_mean_absolute_error: 0.0207\n",
      "Epoch 345/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.5239e-04 - mean_absolute_error: 0.0234\n",
      "Epoch 00345: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5188e-04 - mean_absolute_error: 0.0234 - val_loss: 3.8992e-04 - val_mean_absolute_error: 0.0216\n",
      "Epoch 346/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7247e-04 - mean_absolute_error: 0.0240- ETA: 1s - loss: 4.7241e-04 - mean_absolute_er - ETA: 0s - loss: 4.7286e-04 - mean_absolute_error: 0.\n",
      "Epoch 00346: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7551e-04 - mean_absolute_error: 0.0240 - val_loss: 3.7513e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 347/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7513e-04 - mean_absolute_error: 0.0239\n",
      "Epoch 00347: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7255e-04 - mean_absolute_error: 0.0238 - val_loss: 3.8698e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 348/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8107e-04 - mean_absolute_error: 0.0241- ETA: 3s - loss: 4.6809e\n",
      "Epoch 00348: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8109e-04 - mean_absolute_error: 0.0241 - val_loss: 4.2273e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 349/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 5.0696e-04 - mean_absolute_error: 0.0246\n",
      "Epoch 00349: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 5.0706e-04 - mean_absolute_error: 0.0246 - val_loss: 4.1118e-04 - val_mean_absolute_error: 0.0217\n",
      "Epoch 350/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.9858e-04 - mean_absolute_error: 0.0246- ETA: 5s - loss: 4.3717e-04 - mea - ETA: 2s - loss: 4.8472e-04 - mean_absolute_e - ETA: 1s - loss: 4.8629e-04 - mean_absolute_\n",
      "Epoch 00350: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.9886e-04 - mean_absolute_error: 0.0246 - val_loss: 3.6937e-04 - val_mean_absolute_error: 0.0211\n",
      "Epoch 351/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7343e-04 - mean_absolute_error: 0.0240\n",
      "Epoch 00351: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7518e-04 - mean_absolute_error: 0.0240 - val_loss: 3.8843e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 352/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8306e-04 - mean_absolute_error: 0.0241- ETA: 2s - loss: 4.9280e-04 -\n",
      "Epoch 00352: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8237e-04 - mean_absolute_error: 0.0241 - val_loss: 3.7784e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 353/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.6579e-04 - mean_absolute_error: 0.0238- ETA: 5s\n",
      "Epoch 00353: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.6586e-04 - mean_absolute_error: 0.0238 - val_loss: 3.6066e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 354/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.6311e-04 - mean_absolute_error: 0.0236\n",
      "Epoch 00354: val_loss did not improve from 0.00036\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.6196e-04 - mean_absolute_error: 0.0236 - val_loss: 3.6960e-04 - val_mean_absolute_error: 0.0211\n",
      "Epoch 355/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8280e-04 - mean_absolute_error: 0.0241\n",
      "Epoch 00355: val_loss improved from 0.00036 to 0.00035, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8205e-04 - mean_absolute_error: 0.0241 - val_loss: 3.5287e-04 - val_mean_absolute_error: 0.0205\n",
      "Epoch 356/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7777e-04 - mean_absolute_error: 0.0241\n",
      "Epoch 00356: val_loss improved from 0.00035 to 0.00035, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7605e-04 - mean_absolute_error: 0.0240 - val_loss: 3.4853e-04 - val_mean_absolute_error: 0.0205\n",
      "Epoch 357/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4729e-04 - mean_absolute_error: 0.0231\n",
      "Epoch 00357: val_loss did not improve from 0.00035\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.4548e-04 - mean_absolute_error: 0.0230 - val_loss: 3.8775e-04 - val_mean_absolute_error: 0.0216\n",
      "Epoch 358/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.5259e-04 - mean_absolute_error: 0.0233- ETA: 4s - loss:\n",
      "Epoch 00358: val_loss did not improve from 0.00035\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5249e-04 - mean_absolute_error: 0.0233 - val_loss: 3.8477e-04 - val_mean_absolute_error: 0.0215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.8689e-04 - mean_absolute_error: 0.0243- ETA: 0s - loss: 4.8811e-04 - mean_absolute_error: 0.02\n",
      "Epoch 00359: val_loss did not improve from 0.00035\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.8491e-04 - mean_absolute_error: 0.0243 - val_loss: 3.6534e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 360/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.6302e-04 - mean_absolute_error: 0.0239\n",
      "Epoch 00360: val_loss did not improve from 0.00035\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.6350e-04 - mean_absolute_error: 0.0239 - val_loss: 4.2112e-04 - val_mean_absolute_error: 0.0228\n",
      "Epoch 361/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7370e-04 - mean_absolute_error: 0.0239- ETA: 0s - loss: 4.7309e-04 - mean_absolute_erro\n",
      "Epoch 00361: val_loss did not improve from 0.00035\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7344e-04 - mean_absolute_error: 0.0239 - val_loss: 4.1178e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 362/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.5091e-04 - mean_absolute_error: 0.0233\n",
      "Epoch 00362: val_loss improved from 0.00035 to 0.00035, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5226e-04 - mean_absolute_error: 0.0234 - val_loss: 3.4699e-04 - val_mean_absolute_error: 0.0206\n",
      "Epoch 363/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.5812e-04 - mean_absolute_error: 0.0234\n",
      "Epoch 00363: val_loss did not improve from 0.00035\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5876e-04 - mean_absolute_error: 0.0235 - val_loss: 3.6875e-04 - val_mean_absolute_error: 0.0209\n",
      "Epoch 364/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.6755e-04 - mean_absolute_error: 0.0234\n",
      "Epoch 00364: val_loss improved from 0.00035 to 0.00034, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.6730e-04 - mean_absolute_error: 0.0234 - val_loss: 3.4318e-04 - val_mean_absolute_error: 0.0204\n",
      "Epoch 365/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4849e-04 - mean_absolute_error: 0.0232\n",
      "Epoch 00365: val_loss did not improve from 0.00034\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5095e-04 - mean_absolute_error: 0.0233 - val_loss: 3.5642e-04 - val_mean_absolute_error: 0.0209\n",
      "Epoch 366/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.5957e-04 - mean_absolute_error: 0.0236\n",
      "Epoch 00366: val_loss improved from 0.00034 to 0.00034, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5941e-04 - mean_absolute_error: 0.0236 - val_loss: 3.3653e-04 - val_mean_absolute_error: 0.0204\n",
      "Epoch 367/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.6680e-04 - mean_absolute_error: 0.0236- ETA: 3s - loss: 4.7266e\n",
      "Epoch 00367: val_loss improved from 0.00034 to 0.00033, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.6970e-04 - mean_absolute_error: 0.0237 - val_loss: 3.2932e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 368/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4141e-04 - mean_absolute_error: 0.0233\n",
      "Epoch 00368: val_loss did not improve from 0.00033\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.4064e-04 - mean_absolute_error: 0.0232 - val_loss: 3.6547e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 369/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.5648e-04 - mean_absolute_error: 0.0234\n",
      "Epoch 00369: val_loss did not improve from 0.00033\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5607e-04 - mean_absolute_error: 0.0234 - val_loss: 3.4282e-04 - val_mean_absolute_error: 0.0206\n",
      "Epoch 370/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.3742e-04 - mean_absolute_error: 0.0231- ETA: 3s - loss: 4.1150e-04 - mean_absolute_e - ETA: 2s - loss: 4.1995e-04 - m\n",
      "Epoch 00370: val_loss did not improve from 0.00033\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.3731e-04 - mean_absolute_error: 0.0231 - val_loss: 3.7741e-04 - val_mean_absolute_error: 0.0211\n",
      "Epoch 371/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.5259e-04 - mean_absolute_error: 0.0234\n",
      "Epoch 00371: val_loss did not improve from 0.00033\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5142e-04 - mean_absolute_error: 0.0233 - val_loss: 3.4492e-04 - val_mean_absolute_error: 0.0205\n",
      "Epoch 372/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4836e-04 - mean_absolute_error: 0.0235- ETA: 0s - loss: 4.5478e-04 - mean_absolute_error:\n",
      "Epoch 00372: val_loss did not improve from 0.00033\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.4953e-04 - mean_absolute_error: 0.0235 - val_loss: 3.2950e-04 - val_mean_absolute_error: 0.0198\n",
      "Epoch 373/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4881e-04 - mean_absolute_error: 0.0233\n",
      "Epoch 00373: val_loss did not improve from 0.00033\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5081e-04 - mean_absolute_error: 0.0233 - val_loss: 3.7220e-04 - val_mean_absolute_error: 0.0214\n",
      "Epoch 374/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7254e-04 - mean_absolute_error: 0.0242- ETA: 2s - loss: 4.6524e-04 - mean_absolute_error: 0.02 - ETA: 2s - loss: 4.6288e-04 - me\n",
      "Epoch 00374: val_loss improved from 0.00033 to 0.00032, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7277e-04 - mean_absolute_error: 0.0242 - val_loss: 3.2173e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 375/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4276e-04 - mean_absolute_error: 0.0233\n",
      "Epoch 00375: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.4139e-04 - mean_absolute_error: 0.0232 - val_loss: 3.4242e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 376/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.3824e-04 - mean_absolute_error: 0.0232\n",
      "Epoch 00376: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.3906e-04 - mean_absolute_error: 0.0232 - val_loss: 3.3999e-04 - val_mean_absolute_error: 0.0206\n",
      "Epoch 377/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.7487e-04 - mean_absolute_error: 0.0240\n",
      "Epoch 00377: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.7612e-04 - mean_absolute_error: 0.0240 - val_loss: 3.3465e-04 - val_mean_absolute_error: 0.0203\n",
      "Epoch 378/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4825e-04 - mean_absolute_error: 0.0232- ETA: 2s - loss: 4.2882e-04 - mean\n",
      "Epoch 00378: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.4997e-04 - mean_absolute_error: 0.0232 - val_loss: 3.4736e-04 - val_mean_absolute_error: 0.0210\n",
      "Epoch 379/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.5001e-04 - mean_absolute_error: 0.0235\n",
      "Epoch 00379: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.5013e-04 - mean_absolute_error: 0.0234 - val_loss: 3.6454e-04 - val_mean_absolute_error: 0.0210\n",
      "Epoch 380/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4492e-04 - mean_absolute_error: 0.0233\n",
      "Epoch 00380: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.4436e-04 - mean_absolute_error: 0.0233 - val_loss: 3.5696e-04 - val_mean_absolute_error: 0.0211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4602e-04 - mean_absolute_error: 0.0231\n",
      "Epoch 00381: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.4583e-04 - mean_absolute_error: 0.0231 - val_loss: 3.3934e-04 - val_mean_absolute_error: 0.0201\n",
      "Epoch 382/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2971e-04 - mean_absolute_error: 0.0229- ETA: 0s - loss: 4.2832e-04 - mean_absolute_error\n",
      "Epoch 00382: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2981e-04 - mean_absolute_error: 0.0229 - val_loss: 3.4393e-04 - val_mean_absolute_error: 0.0206\n",
      "Epoch 383/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.3492e-04 - mean_absolute_error: 0.0230\n",
      "Epoch 00383: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.3284e-04 - mean_absolute_error: 0.0229 - val_loss: 3.3222e-04 - val_mean_absolute_error: 0.0206\n",
      "Epoch 384/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2763e-04 - mean_absolute_error: 0.0227\n",
      "Epoch 00384: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2795e-04 - mean_absolute_error: 0.0227 - val_loss: 3.5490e-04 - val_mean_absolute_error: 0.0207\n",
      "Epoch 385/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2419e-04 - mean_absolute_error: 0.0228\n",
      "Epoch 00385: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2327e-04 - mean_absolute_error: 0.0227 - val_loss: 3.8350e-04 - val_mean_absolute_error: 0.0217\n",
      "Epoch 386/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2353e-04 - mean_absolute_error: 0.0226\n",
      "Epoch 00386: val_loss improved from 0.00032 to 0.00032, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2312e-04 - mean_absolute_error: 0.0226 - val_loss: 3.1795e-04 - val_mean_absolute_error: 0.0196\n",
      "Epoch 387/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2544e-04 - mean_absolute_error: 0.0226\n",
      "Epoch 00387: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2532e-04 - mean_absolute_error: 0.0226 - val_loss: 3.6388e-04 - val_mean_absolute_error: 0.0210\n",
      "Epoch 388/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2478e-04 - mean_absolute_error: 0.0228\n",
      "Epoch 00388: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2562e-04 - mean_absolute_error: 0.0228 - val_loss: 3.3533e-04 - val_mean_absolute_error: 0.0204\n",
      "Epoch 389/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.4406e-04 - mean_absolute_error: 0.0232\n",
      "Epoch 00389: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.4498e-04 - mean_absolute_error: 0.0232 - val_loss: 3.4049e-04 - val_mean_absolute_error: 0.0207\n",
      "Epoch 390/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0848e-04 - mean_absolute_error: 0.0224\n",
      "Epoch 00390: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0725e-04 - mean_absolute_error: 0.0224 - val_loss: 3.2242e-04 - val_mean_absolute_error: 0.0197\n",
      "Epoch 391/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1027e-04 - mean_absolute_error: 0.0224\n",
      "Epoch 00391: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1093e-04 - mean_absolute_error: 0.0224 - val_loss: 3.2288e-04 - val_mean_absolute_error: 0.0200\n",
      "Epoch 392/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2880e-04 - mean_absolute_error: 0.0230- ETA: 1s - loss: 4.2295e-04 - mean_absol\n",
      "Epoch 00392: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2889e-04 - mean_absolute_error: 0.0231 - val_loss: 3.3566e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 393/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.3253e-04 - mean_absolute_error: 0.0231\n",
      "Epoch 00393: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.3300e-04 - mean_absolute_error: 0.0231 - val_loss: 3.2568e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 394/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1438e-04 - mean_absolute_error: 0.0225\n",
      "Epoch 00394: val_loss did not improve from 0.00032\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1495e-04 - mean_absolute_error: 0.0225 - val_loss: 3.3720e-04 - val_mean_absolute_error: 0.0205\n",
      "Epoch 395/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1709e-04 - mean_absolute_error: 0.0226\n",
      "Epoch 00395: val_loss improved from 0.00032 to 0.00030, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1765e-04 - mean_absolute_error: 0.0226 - val_loss: 3.0458e-04 - val_mean_absolute_error: 0.0195\n",
      "Epoch 396/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0545e-04 - mean_absolute_error: 0.0221- ETA: 4s - lo\n",
      "Epoch 00396: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0548e-04 - mean_absolute_error: 0.0221 - val_loss: 3.0744e-04 - val_mean_absolute_error: 0.0196\n",
      "Epoch 397/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0275e-04 - mean_absolute_error: 0.0223- ETA: 0s - loss: 4.0260e-04 - mean_absolute_error: 0.022\n",
      "Epoch 00397: val_loss improved from 0.00030 to 0.00030, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0169e-04 - mean_absolute_error: 0.0223 - val_loss: 3.0382e-04 - val_mean_absolute_error: 0.0195\n",
      "Epoch 398/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0875e-04 - mean_absolute_error: 0.0225\n",
      "Epoch 00398: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0763e-04 - mean_absolute_error: 0.0225 - val_loss: 3.4048e-04 - val_mean_absolute_error: 0.0204\n",
      "Epoch 399/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1196e-04 - mean_absolute_error: 0.0222- ETA: 1s - loss: 4.1617e-04 - mean_absolute_err - ETA: 0s - loss: 4.1433e-04 - mean_absolute_error: 0\n",
      "Epoch 00399: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1318e-04 - mean_absolute_error: 0.0223 - val_loss: 3.5324e-04 - val_mean_absolute_error: 0.0209\n",
      "Epoch 400/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2849e-04 - mean_absolute_error: 0.0231\n",
      "Epoch 00400: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2963e-04 - mean_absolute_error: 0.0231 - val_loss: 3.3680e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 401/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1898e-04 - mean_absolute_error: 0.0224\n",
      "Epoch 00401: val_loss improved from 0.00030 to 0.00030, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1828e-04 - mean_absolute_error: 0.0224 - val_loss: 2.9898e-04 - val_mean_absolute_error: 0.0191\n",
      "Epoch 402/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0496e-04 - mean_absolute_error: 0.0222\n",
      "Epoch 00402: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0619e-04 - mean_absolute_error: 0.0222 - val_loss: 3.2252e-04 - val_mean_absolute_error: 0.0197\n",
      "Epoch 403/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0830e-04 - mean_absolute_error: 0.0222- ETA: 3s - loss: 4.4070e-\n",
      "Epoch 00403: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0783e-04 - mean_absolute_error: 0.0222 - val_loss: 3.2605e-04 - val_mean_absolute_error: 0.0200\n",
      "Epoch 404/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2244e-04 - mean_absolute_error: 0.0226\n",
      "Epoch 00404: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2085e-04 - mean_absolute_error: 0.0226 - val_loss: 3.0677e-04 - val_mean_absolute_error: 0.0193\n",
      "Epoch 405/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9832e-04 - mean_absolute_error: 0.0220- ETA: 3s - loss: 4.0941e-04 - ETA: 0s - loss: 3.9981e-04 - mean_absolute_error: 0\n",
      "Epoch 00405: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9835e-04 - mean_absolute_error: 0.0220 - val_loss: 3.1666e-04 - val_mean_absolute_error: 0.0195\n",
      "Epoch 406/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0260e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00406: val_loss improved from 0.00030 to 0.00030, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0362e-04 - mean_absolute_error: 0.0221 - val_loss: 2.9866e-04 - val_mean_absolute_error: 0.0193\n",
      "Epoch 407/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2904e-04 - mean_absolute_error: 0.0229\n",
      "Epoch 00407: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.3014e-04 - mean_absolute_error: 0.0229 - val_loss: 4.2617e-04 - val_mean_absolute_error: 0.0233\n",
      "Epoch 408/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1773e-04 - mean_absolute_error: 0.0226- ETA: 1s - loss: 4.2356e-04 - mean_absolu\n",
      "Epoch 00408: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1789e-04 - mean_absolute_error: 0.0226 - val_loss: 3.9469e-04 - val_mean_absolute_error: 0.0219\n",
      "Epoch 409/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0304e-04 - mean_absolute_error: 0.0223- ETA: 0s - loss: 4.0604e-04 - mean_absolute_error: 0.\n",
      "Epoch 00409: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0291e-04 - mean_absolute_error: 0.0223 - val_loss: 3.1054e-04 - val_mean_absolute_error: 0.0193\n",
      "Epoch 410/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9107e-04 - mean_absolute_error: 0.0219\n",
      "Epoch 00410: val_loss did not improve from 0.00030\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9224e-04 - mean_absolute_error: 0.0219 - val_loss: 3.2715e-04 - val_mean_absolute_error: 0.0203\n",
      "Epoch 411/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0588e-04 - mean_absolute_error: 0.0222- ETA: 3s - loss: 4.4694e-04\n",
      "Epoch 00411: val_loss improved from 0.00030 to 0.00029, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0640e-04 - mean_absolute_error: 0.0222 - val_loss: 2.9058e-04 - val_mean_absolute_error: 0.0190\n",
      "Epoch 412/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2000e-04 - mean_absolute_error: 0.0223\n",
      "Epoch 00412: val_loss did not improve from 0.00029\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.2258e-04 - mean_absolute_error: 0.0224 - val_loss: 2.9340e-04 - val_mean_absolute_error: 0.0192\n",
      "Epoch 413/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1625e-04 - mean_absolute_error: 0.0225\n",
      "Epoch 00413: val_loss did not improve from 0.00029\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1680e-04 - mean_absolute_error: 0.0225 - val_loss: 3.2410e-04 - val_mean_absolute_error: 0.0197\n",
      "Epoch 414/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.2037e-04 - mean_absolute_error: 0.0226\n",
      "Epoch 00414: val_loss did not improve from 0.00029\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1996e-04 - mean_absolute_error: 0.0226 - val_loss: 3.3144e-04 - val_mean_absolute_error: 0.0201\n",
      "Epoch 415/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0114e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00415: val_loss did not improve from 0.00029\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0196e-04 - mean_absolute_error: 0.0221 - val_loss: 2.9085e-04 - val_mean_absolute_error: 0.0188\n",
      "Epoch 416/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9628e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00416: val_loss improved from 0.00029 to 0.00029, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9779e-04 - mean_absolute_error: 0.0220 - val_loss: 2.8765e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 417/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1139e-04 - mean_absolute_error: 0.0224\n",
      "Epoch 00417: val_loss did not improve from 0.00029\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.1064e-04 - mean_absolute_error: 0.0224 - val_loss: 3.1446e-04 - val_mean_absolute_error: 0.0194\n",
      "Epoch 418/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9185e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 00418: val_loss did not improve from 0.00029\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9202e-04 - mean_absolute_error: 0.0218 - val_loss: 3.0250e-04 - val_mean_absolute_error: 0.0191\n",
      "Epoch 419/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8808e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 00419: val_loss did not improve from 0.00029\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8817e-04 - mean_absolute_error: 0.0218 - val_loss: 2.9662e-04 - val_mean_absolute_error: 0.0193\n",
      "Epoch 420/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8456e-04 - mean_absolute_error: 0.0217- ETA: 3s - loss: 3.8836e-0\n",
      "Epoch 00420: val_loss did not improve from 0.00029\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8501e-04 - mean_absolute_error: 0.0217 - val_loss: 3.2305e-04 - val_mean_absolute_error: 0.0200\n",
      "Epoch 421/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9487e-04 - mean_absolute_error: 0.0219- ETA: 2s - loss: 4.0823e-04 - m\n",
      "Epoch 00421: val_loss improved from 0.00029 to 0.00028, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9352e-04 - mean_absolute_error: 0.0219 - val_loss: 2.7827e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 422/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9576e-04 - mean_absolute_error: 0.0221- ETA: 0s - loss: 3.9478e-04 - mean_absolute_error: 0\n",
      "Epoch 00422: val_loss did not improve from 0.00028\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9567e-04 - mean_absolute_error: 0.0221 - val_loss: 2.8219e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 423/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8572e-04 - mean_absolute_error: 0.0216- ETA: 3s - loss: 3.\n",
      "Epoch 00423: val_loss did not improve from 0.00028\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8575e-04 - mean_absolute_error: 0.0216 - val_loss: 3.3040e-04 - val_mean_absolute_error: 0.0200\n",
      "Epoch 424/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7800e-04 - mean_absolute_error: 0.0215\n",
      "Epoch 00424: val_loss did not improve from 0.00028\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7757e-04 - mean_absolute_error: 0.0215 - val_loss: 2.9455e-04 - val_mean_absolute_error: 0.0192\n",
      "Epoch 425/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8011e-04 - mean_absolute_error: 0.0214\n",
      "Epoch 00425: val_loss did not improve from 0.00028\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7952e-04 - mean_absolute_error: 0.0214 - val_loss: 2.9771e-04 - val_mean_absolute_error: 0.0192\n",
      "Epoch 426/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9104e-04 - mean_absolute_error: 0.0219\n",
      "Epoch 00426: val_loss did not improve from 0.00028\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9189e-04 - mean_absolute_error: 0.0219 - val_loss: 3.1100e-04 - val_mean_absolute_error: 0.0195\n",
      "Epoch 427/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9235e-04 - mean_absolute_error: 0.0219\n",
      "Epoch 00427: val_loss improved from 0.00028 to 0.00027, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9160e-04 - mean_absolute_error: 0.0219 - val_loss: 2.7474e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 428/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9429e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00428: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9440e-04 - mean_absolute_error: 0.0220 - val_loss: 2.8249e-04 - val_mean_absolute_error: 0.0188\n",
      "Epoch 429/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9846e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00429: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9891e-04 - mean_absolute_error: 0.0220 - val_loss: 3.1447e-04 - val_mean_absolute_error: 0.0194\n",
      "Epoch 430/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8708e-04 - mean_absolute_error: 0.0217\n",
      "Epoch 00430: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8905e-04 - mean_absolute_error: 0.0218 - val_loss: 3.2389e-04 - val_mean_absolute_error: 0.0201\n",
      "Epoch 431/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8962e-04 - mean_absolute_error: 0.0218- ETA: 1s - loss: 3.7451e-04 - mean_absolute_err - ETA: 0s - loss: 3.8081e-04 - mean_absolute_error\n",
      "Epoch 00431: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8995e-04 - mean_absolute_error: 0.0218 - val_loss: 3.0042e-04 - val_mean_absolute_error: 0.0191\n",
      "Epoch 432/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8926e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 00432: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8901e-04 - mean_absolute_error: 0.0218 - val_loss: 2.7751e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 433/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9425e-04 - mean_absolute_error: 0.0219\n",
      "Epoch 00433: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9416e-04 - mean_absolute_error: 0.0219 - val_loss: 2.8302e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 434/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.1036e-04 - mean_absolute_error: 0.0225\n",
      "Epoch 00434: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0952e-04 - mean_absolute_error: 0.0225 - val_loss: 3.1297e-04 - val_mean_absolute_error: 0.0197\n",
      "Epoch 435/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7953e-04 - mean_absolute_error: 0.0215\n",
      "Epoch 00435: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7904e-04 - mean_absolute_error: 0.0215 - val_loss: 2.8934e-04 - val_mean_absolute_error: 0.0188\n",
      "Epoch 436/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8573e-04 - mean_absolute_error: 0.0216\n",
      "Epoch 00436: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8666e-04 - mean_absolute_error: 0.0216 - val_loss: 2.8369e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 437/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7669e-04 - mean_absolute_error: 0.0214\n",
      "Epoch 00437: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7727e-04 - mean_absolute_error: 0.0215 - val_loss: 3.3934e-04 - val_mean_absolute_error: 0.0206\n",
      "Epoch 438/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8351e-04 - mean_absolute_error: 0.0217- ETA: 4s - loss: 3\n",
      "Epoch 00438: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8439e-04 - mean_absolute_error: 0.0217 - val_loss: 2.9790e-04 - val_mean_absolute_error: 0.0190\n",
      "Epoch 439/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9261e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 00439: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9235e-04 - mean_absolute_error: 0.0218 - val_loss: 2.7727e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 440/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8286e-04 - mean_absolute_error: 0.0217- ETA: \n",
      "Epoch 00440: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8431e-04 - mean_absolute_error: 0.0217 - val_loss: 3.1115e-04 - val_mean_absolute_error: 0.0194\n",
      "Epoch 441/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8451e-04 - mean_absolute_error: 0.0217- ETA: 3s - loss: 3.6\n",
      "Epoch 00441: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8396e-04 - mean_absolute_error: 0.0216 - val_loss: 2.8614e-04 - val_mean_absolute_error: 0.0184\n",
      "Epoch 442/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7667e-04 - mean_absolute_error: 0.0214\n",
      "Epoch 00442: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7783e-04 - mean_absolute_error: 0.0215 - val_loss: 2.8166e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 443/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7779e-04 - mean_absolute_error: 0.0215- ETA: 2s - loss: 3.7660e-04 -\n",
      "Epoch 00443: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7608e-04 - mean_absolute_error: 0.0214 - val_loss: 2.9043e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 444/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7790e-04 - mean_absolute_error: 0.0216\n",
      "Epoch 00444: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7796e-04 - mean_absolute_error: 0.0216 - val_loss: 2.7843e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 445/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7230e-04 - mean_absolute_error: 0.0213\n",
      "Epoch 00445: val_loss did not improve from 0.00027\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7182e-04 - mean_absolute_error: 0.0213 - val_loss: 3.2198e-04 - val_mean_absolute_error: 0.0199\n",
      "Epoch 446/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8608e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 00446: val_loss improved from 0.00027 to 0.00026, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8734e-04 - mean_absolute_error: 0.0218 - val_loss: 2.6017e-04 - val_mean_absolute_error: 0.0177\n",
      "Epoch 447/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9583e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00447: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9667e-04 - mean_absolute_error: 0.0220 - val_loss: 2.7674e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 448/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.9127e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 00448: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.9083e-04 - mean_absolute_error: 0.0220 - val_loss: 2.8421e-04 - val_mean_absolute_error: 0.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7729e-04 - mean_absolute_error: 0.0215\n",
      "Epoch 00449: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7891e-04 - mean_absolute_error: 0.0216 - val_loss: 3.0485e-04 - val_mean_absolute_error: 0.0191\n",
      "Epoch 450/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7613e-04 - mean_absolute_error: 0.0214\n",
      "Epoch 00450: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7690e-04 - mean_absolute_error: 0.0215 - val_loss: 3.0163e-04 - val_mean_absolute_error: 0.0193\n",
      "Epoch 451/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7700e-04 - mean_absolute_error: 0.0215- ETA: 4s - los\n",
      "Epoch 00451: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7669e-04 - mean_absolute_error: 0.0215 - val_loss: 2.7233e-04 - val_mean_absolute_error: 0.0182\n",
      "Epoch 452/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7633e-04 - mean_absolute_error: 0.0215- ETA: 4s - loss:\n",
      "Epoch 00452: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7824e-04 - mean_absolute_error: 0.0216 - val_loss: 2.9037e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 453/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8474e-04 - mean_absolute_error: 0.0216- ETA: 3s - loss: 3.7963e-0\n",
      "Epoch 00453: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8371e-04 - mean_absolute_error: 0.0216 - val_loss: 2.8058e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 454/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8765e-04 - mean_absolute_error: 0.0219\n",
      "Epoch 00454: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8808e-04 - mean_absolute_error: 0.0219 - val_loss: 2.9519e-04 - val_mean_absolute_error: 0.0189\n",
      "Epoch 455/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 4.0024e-04 - mean_absolute_error: 0.0220- ETA: 1s - loss: 4.1897e-04 - mean_absolu\n",
      "Epoch 00455: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 4.0032e-04 - mean_absolute_error: 0.0220 - val_loss: 2.9847e-04 - val_mean_absolute_error: 0.0192\n",
      "Epoch 456/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6711e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00456: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6739e-04 - mean_absolute_error: 0.0213 - val_loss: 2.7377e-04 - val_mean_absolute_error: 0.0184\n",
      "Epoch 457/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5354e-04 - mean_absolute_error: 0.0208- ETA: 2s - loss: 3.2900e-04 -\n",
      "Epoch 00457: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5469e-04 - mean_absolute_error: 0.0209 - val_loss: 2.7442e-04 - val_mean_absolute_error: 0.0185\n",
      "Epoch 458/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6256e-04 - mean_absolute_error: 0.0209\n",
      "Epoch 00458: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6240e-04 - mean_absolute_error: 0.0209 - val_loss: 3.0960e-04 - val_mean_absolute_error: 0.0193\n",
      "Epoch 459/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7133e-04 - mean_absolute_error: 0.0213\n",
      "Epoch 00459: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7029e-04 - mean_absolute_error: 0.0213 - val_loss: 2.6732e-04 - val_mean_absolute_error: 0.0180\n",
      "Epoch 460/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7807e-04 - mean_absolute_error: 0.0215\n",
      "Epoch 00460: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7836e-04 - mean_absolute_error: 0.0215 - val_loss: 2.6478e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 461/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6242e-04 - mean_absolute_error: 0.0211\n",
      "Epoch 00461: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6328e-04 - mean_absolute_error: 0.0212 - val_loss: 3.2226e-04 - val_mean_absolute_error: 0.0202\n",
      "Epoch 462/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7700e-04 - mean_absolute_error: 0.0215- ETA: 3s - loss: 3.5733e-04 \n",
      "Epoch 00462: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7730e-04 - mean_absolute_error: 0.0215 - val_loss: 2.8441e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 463/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7063e-04 - mean_absolute_error: 0.0214\n",
      "Epoch 00463: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7120e-04 - mean_absolute_error: 0.0214 - val_loss: 2.7024e-04 - val_mean_absolute_error: 0.0182\n",
      "Epoch 464/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6037e-04 - mean_absolute_error: 0.0210\n",
      "Epoch 00464: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6067e-04 - mean_absolute_error: 0.0210 - val_loss: 3.2287e-04 - val_mean_absolute_error: 0.0201\n",
      "Epoch 465/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5345e-04 - mean_absolute_error: 0.0209- ETA: 2s - loss: 3.5860e-04 -\n",
      "Epoch 00465: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5403e-04 - mean_absolute_error: 0.0209 - val_loss: 2.6424e-04 - val_mean_absolute_error: 0.0179\n",
      "Epoch 466/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6362e-04 - mean_absolute_error: 0.0212- ETA: 1s - loss: 3.6126e-04 - mean_absolute_er\n",
      "Epoch 00466: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6272e-04 - mean_absolute_error: 0.0212 - val_loss: 3.1891e-04 - val_mean_absolute_error: 0.0196\n",
      "Epoch 467/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6910e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00467: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6871e-04 - mean_absolute_error: 0.0212 - val_loss: 2.8114e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 468/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6632e-04 - mean_absolute_error: 0.0212- ETA: 2s - loss: 3.7975e-04 - \n",
      "Epoch 00468: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6555e-04 - mean_absolute_error: 0.0212 - val_loss: 2.8917e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 469/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5257e-04 - mean_absolute_error: 0.0208\n",
      "Epoch 00469: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5112e-04 - mean_absolute_error: 0.0208 - val_loss: 2.6263e-04 - val_mean_absolute_error: 0.0179\n",
      "Epoch 470/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5292e-04 - mean_absolute_error: 0.0208- ETA: 5s\n",
      "Epoch 00470: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5328e-04 - mean_absolute_error: 0.0208 - val_loss: 2.6947e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 471/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6497e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00471: val_loss improved from 0.00026 to 0.00026, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6487e-04 - mean_absolute_error: 0.0212 - val_loss: 2.5700e-04 - val_mean_absolute_error: 0.0175\n",
      "Epoch 472/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5378e-04 - mean_absolute_error: 0.0208\n",
      "Epoch 00472: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5339e-04 - mean_absolute_error: 0.0207 - val_loss: 2.6597e-04 - val_mean_absolute_error: 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7153e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00473: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.7031e-04 - mean_absolute_error: 0.0211 - val_loss: 2.7655e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 474/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5583e-04 - mean_absolute_error: 0.0209- ETA: 3s - loss: 3.5\n",
      "Epoch 00474: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5551e-04 - mean_absolute_error: 0.0209 - val_loss: 2.8172e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 475/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4981e-04 - mean_absolute_error: 0.0207- ETA: 4s \n",
      "Epoch 00475: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5019e-04 - mean_absolute_error: 0.0207 - val_loss: 2.9068e-04 - val_mean_absolute_error: 0.0187\n",
      "Epoch 476/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5255e-04 - mean_absolute_error: 0.0207- ETA: 3s - loss: 3.4924e-0 - ETA: 0s - loss: 3.5519e-04 - mean_absolute_error: 0\n",
      "Epoch 00476: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5286e-04 - mean_absolute_error: 0.0207 - val_loss: 3.1858e-04 - val_mean_absolute_error: 0.0192\n",
      "Epoch 477/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6833e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00477: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6797e-04 - mean_absolute_error: 0.0212 - val_loss: 3.1502e-04 - val_mean_absolute_error: 0.0197\n",
      "Epoch 478/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6481e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00478: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6605e-04 - mean_absolute_error: 0.0212 - val_loss: 3.0872e-04 - val_mean_absolute_error: 0.0192\n",
      "Epoch 479/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5557e-04 - mean_absolute_error: 0.0208\n",
      "Epoch 00479: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5652e-04 - mean_absolute_error: 0.0209 - val_loss: 2.7465e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 480/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4886e-04 - mean_absolute_error: 0.0206\n",
      "Epoch 00480: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4798e-04 - mean_absolute_error: 0.0205 - val_loss: 2.6425e-04 - val_mean_absolute_error: 0.0179\n",
      "Epoch 481/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5113e-04 - mean_absolute_error: 0.0208\n",
      "Epoch 00481: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5076e-04 - mean_absolute_error: 0.0208 - val_loss: 2.6158e-04 - val_mean_absolute_error: 0.0177\n",
      "Epoch 482/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4453e-04 - mean_absolute_error: 0.0207\n",
      "Epoch 00482: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4546e-04 - mean_absolute_error: 0.0207 - val_loss: 2.5833e-04 - val_mean_absolute_error: 0.0175\n",
      "Epoch 483/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5604e-04 - mean_absolute_error: 0.0210- ETA: 2s - loss: 3.5181e-04 - \n",
      "Epoch 00483: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5485e-04 - mean_absolute_error: 0.0210 - val_loss: 2.6832e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 484/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6407e-04 - mean_absolute_error: 0.0211\n",
      "Epoch 00484: val_loss did not improve from 0.00026\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6457e-04 - mean_absolute_error: 0.0211 - val_loss: 2.7544e-04 - val_mean_absolute_error: 0.0183\n",
      "Epoch 485/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6919e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00485: val_loss improved from 0.00026 to 0.00025, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6889e-04 - mean_absolute_error: 0.0212 - val_loss: 2.4526e-04 - val_mean_absolute_error: 0.0171\n",
      "Epoch 486/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4796e-04 - mean_absolute_error: 0.0206- ETA: 3s - loss: 3.5945\n",
      "Epoch 00486: val_loss did not improve from 0.00025\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4866e-04 - mean_absolute_error: 0.0206 - val_loss: 2.5329e-04 - val_mean_absolute_error: 0.0174\n",
      "Epoch 487/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4439e-04 - mean_absolute_error: 0.0204- ETA: 2s - loss: 3.3110e-04 - mean_\n",
      "Epoch 00487: val_loss did not improve from 0.00025\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4436e-04 - mean_absolute_error: 0.0204 - val_loss: 2.9549e-04 - val_mean_absolute_error: 0.0191\n",
      "Epoch 488/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5020e-04 - mean_absolute_error: 0.0208\n",
      "Epoch 00488: val_loss improved from 0.00025 to 0.00024, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4933e-04 - mean_absolute_error: 0.0208 - val_loss: 2.4207e-04 - val_mean_absolute_error: 0.0172\n",
      "Epoch 489/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6544e-04 - mean_absolute_error: 0.0211\n",
      "Epoch 00489: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6417e-04 - mean_absolute_error: 0.0211 - val_loss: 3.1317e-04 - val_mean_absolute_error: 0.0194\n",
      "Epoch 490/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.7003e-04 - mean_absolute_error: 0.0212\n",
      "Epoch 00490: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6990e-04 - mean_absolute_error: 0.0213 - val_loss: 3.1948e-04 - val_mean_absolute_error: 0.0200\n",
      "Epoch 491/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.8323e-04 - mean_absolute_error: 0.021 - ETA: 0s - loss: 3.8494e-04 - mean_absolute_error: 0.0217\n",
      "Epoch 00491: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.8391e-04 - mean_absolute_error: 0.0216 - val_loss: 2.5153e-04 - val_mean_absolute_error: 0.0173\n",
      "Epoch 492/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4963e-04 - mean_absolute_error: 0.0206- ETA: 2s - loss: 3.4560e-04 - mea\n",
      "Epoch 00492: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4936e-04 - mean_absolute_error: 0.0206 - val_loss: 2.5619e-04 - val_mean_absolute_error: 0.0175\n",
      "Epoch 493/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.6362e-04 - mean_absolute_error: 0.0210\n",
      "Epoch 00493: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.6307e-04 - mean_absolute_error: 0.0210 - val_loss: 2.4762e-04 - val_mean_absolute_error: 0.0171\n",
      "Epoch 494/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4705e-04 - mean_absolute_error: 0.0206- ETA: 2s - loss: 3.3771e-04 - mean_absolute_erro - ETA: 1s - loss: 3.4584e-04 - mean_absolut\n",
      "Epoch 00494: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4567e-04 - mean_absolute_error: 0.0205 - val_loss: 2.7544e-04 - val_mean_absolute_error: 0.0182\n",
      "Epoch 495/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4938e-04 - mean_absolute_error: 0.0207- ETA: 4s - lo\n",
      "Epoch 00495: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5072e-04 - mean_absolute_error: 0.0207 - val_loss: 2.4997e-04 - val_mean_absolute_error: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4938e-04 - mean_absolute_error: 0.0207\n",
      "Epoch 00496: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4854e-04 - mean_absolute_error: 0.0207 - val_loss: 2.4453e-04 - val_mean_absolute_error: 0.0171\n",
      "Epoch 497/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.3827e-04 - mean_absolute_error: 0.0204\n",
      "Epoch 00497: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.3862e-04 - mean_absolute_error: 0.0204 - val_loss: 2.5931e-04 - val_mean_absolute_error: 0.0175\n",
      "Epoch 498/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5539e-04 - mean_absolute_error: 0.0208- ETA: 0s - loss: 3.5775e-04 - mean_absolute_error: 0.02\n",
      "Epoch 00498: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5490e-04 - mean_absolute_error: 0.0208 - val_loss: 2.6402e-04 - val_mean_absolute_error: 0.0177\n",
      "Epoch 499/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.4955e-04 - mean_absolute_error: 0.0206\n",
      "Epoch 00499: val_loss did not improve from 0.00024\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.4915e-04 - mean_absolute_error: 0.0206 - val_loss: 2.7491e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 500/500\n",
      "3392/3420 [============================>.] - ETA: 0s - loss: 3.5566e-04 - mean_absolute_error: 0.0207\n",
      "Epoch 00500: val_loss improved from 0.00024 to 0.00024, saving model to results\\2022-02-13_GLD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "3420/3420 [==============================] - 6s 2ms/sample - loss: 3.5535e-04 - mean_absolute_error: 0.0207 - val_loss: 2.4084e-04 - val_mean_absolute_error: 0.0168\n"
     ]
    }
   ],
   "source": [
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "Now that we've trained our model, let's evaluate it and see how it's doing on the testing set, the below function takes a pandas Dataframe and plots the true and predicted prices in the same plot using matplotlib, we'll use it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below function takes the model and the data that was returned by create_model() and load_data() functions respectively, \n",
    "# and constructs a dataframe in which it includes the predicted adjclose along with true future adjclose, as well as \n",
    "# calculating buy and sell profit\n",
    "\n",
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The last function we gonna define is the one that's responsible for predicting the next future price:\n",
    "\n",
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_15</th>\n",
       "      <th>true_adjclose_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-02-10</th>\n",
       "      <td>41.529999</td>\n",
       "      <td>41.840000</td>\n",
       "      <td>41.450001</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>7774500</td>\n",
       "      <td>GLD</td>\n",
       "      <td>42.289406</td>\n",
       "      <td>43.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-11</th>\n",
       "      <td>41.889999</td>\n",
       "      <td>42.160000</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>42.080002</td>\n",
       "      <td>42.080002</td>\n",
       "      <td>1896500</td>\n",
       "      <td>GLD</td>\n",
       "      <td>42.646286</td>\n",
       "      <td>43.470001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-16</th>\n",
       "      <td>42.320000</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>42.200001</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>1820400</td>\n",
       "      <td>GLD</td>\n",
       "      <td>43.380287</td>\n",
       "      <td>44.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-23</th>\n",
       "      <td>43.290001</td>\n",
       "      <td>43.549999</td>\n",
       "      <td>43.150002</td>\n",
       "      <td>43.419998</td>\n",
       "      <td>43.419998</td>\n",
       "      <td>1534900</td>\n",
       "      <td>GLD</td>\n",
       "      <td>43.330578</td>\n",
       "      <td>44.310001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-15</th>\n",
       "      <td>44.230000</td>\n",
       "      <td>44.230000</td>\n",
       "      <td>43.930000</td>\n",
       "      <td>44.060001</td>\n",
       "      <td>44.060001</td>\n",
       "      <td>1254900</td>\n",
       "      <td>GLD</td>\n",
       "      <td>43.707573</td>\n",
       "      <td>42.630001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open       high        low      close   adjclose   volume  \\\n",
       "2005-02-10  41.529999  41.840000  41.450001  41.750000  41.750000  7774500   \n",
       "2005-02-11  41.889999  42.160000  41.830002  42.080002  42.080002  1896500   \n",
       "2005-02-16  42.320000  42.599998  42.200001  42.520000  42.520000  1820400   \n",
       "2005-02-23  43.290001  43.549999  43.150002  43.419998  43.419998  1534900   \n",
       "2005-03-15  44.230000  44.230000  43.930000  44.060001  44.060001  1254900   \n",
       "\n",
       "           ticker  adjclose_15  true_adjclose_15  \n",
       "2005-02-10    GLD    42.289406         43.380001  \n",
       "2005-02-11    GLD    42.646286         43.470001  \n",
       "2005-02-16    GLD    43.380287         44.200001  \n",
       "2005-02-23    GLD    43.330578         44.310001  \n",
       "2005-03-15    GLD    43.707573         42.630001  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 166.04$\n",
      "huber_loss loss: 0.00024084196957332022\n",
      "Mean Absolute Error: 43.82189736486451\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_15</th>\n",
       "      <th>true_adjclose_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-02-10</th>\n",
       "      <td>41.529999</td>\n",
       "      <td>41.840000</td>\n",
       "      <td>41.450001</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>7774500</td>\n",
       "      <td>GLD</td>\n",
       "      <td>42.289406</td>\n",
       "      <td>43.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-11</th>\n",
       "      <td>41.889999</td>\n",
       "      <td>42.160000</td>\n",
       "      <td>41.830002</td>\n",
       "      <td>42.080002</td>\n",
       "      <td>42.080002</td>\n",
       "      <td>1896500</td>\n",
       "      <td>GLD</td>\n",
       "      <td>42.646286</td>\n",
       "      <td>43.470001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-16</th>\n",
       "      <td>42.320000</td>\n",
       "      <td>42.599998</td>\n",
       "      <td>42.200001</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>1820400</td>\n",
       "      <td>GLD</td>\n",
       "      <td>43.380287</td>\n",
       "      <td>44.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-23</th>\n",
       "      <td>43.290001</td>\n",
       "      <td>43.549999</td>\n",
       "      <td>43.150002</td>\n",
       "      <td>43.419998</td>\n",
       "      <td>43.419998</td>\n",
       "      <td>1534900</td>\n",
       "      <td>GLD</td>\n",
       "      <td>43.330578</td>\n",
       "      <td>44.310001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-15</th>\n",
       "      <td>44.230000</td>\n",
       "      <td>44.230000</td>\n",
       "      <td>43.930000</td>\n",
       "      <td>44.060001</td>\n",
       "      <td>44.060001</td>\n",
       "      <td>1254900</td>\n",
       "      <td>GLD</td>\n",
       "      <td>43.707573</td>\n",
       "      <td>42.630001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-16</th>\n",
       "      <td>44.290001</td>\n",
       "      <td>44.349998</td>\n",
       "      <td>44.200001</td>\n",
       "      <td>44.310001</td>\n",
       "      <td>44.310001</td>\n",
       "      <td>2223300</td>\n",
       "      <td>GLD</td>\n",
       "      <td>43.898426</td>\n",
       "      <td>42.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-22</th>\n",
       "      <td>43.209999</td>\n",
       "      <td>43.220001</td>\n",
       "      <td>42.549999</td>\n",
       "      <td>42.650002</td>\n",
       "      <td>42.650002</td>\n",
       "      <td>2609400</td>\n",
       "      <td>GLD</td>\n",
       "      <td>42.940781</td>\n",
       "      <td>42.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-24</th>\n",
       "      <td>42.509998</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>42.369999</td>\n",
       "      <td>42.389999</td>\n",
       "      <td>42.389999</td>\n",
       "      <td>1466300</td>\n",
       "      <td>GLD</td>\n",
       "      <td>42.825783</td>\n",
       "      <td>42.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-07</th>\n",
       "      <td>42.770000</td>\n",
       "      <td>42.810001</td>\n",
       "      <td>42.529999</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>2853000</td>\n",
       "      <td>GLD</td>\n",
       "      <td>42.657501</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-08</th>\n",
       "      <td>42.480000</td>\n",
       "      <td>42.709999</td>\n",
       "      <td>42.459999</td>\n",
       "      <td>42.689999</td>\n",
       "      <td>42.689999</td>\n",
       "      <td>1002100</td>\n",
       "      <td>GLD</td>\n",
       "      <td>42.648254</td>\n",
       "      <td>43.349998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open       high        low      close   adjclose   volume  \\\n",
       "2005-02-10  41.529999  41.840000  41.450001  41.750000  41.750000  7774500   \n",
       "2005-02-11  41.889999  42.160000  41.830002  42.080002  42.080002  1896500   \n",
       "2005-02-16  42.320000  42.599998  42.200001  42.520000  42.520000  1820400   \n",
       "2005-02-23  43.290001  43.549999  43.150002  43.419998  43.419998  1534900   \n",
       "2005-03-15  44.230000  44.230000  43.930000  44.060001  44.060001  1254900   \n",
       "2005-03-16  44.290001  44.349998  44.200001  44.310001  44.310001  2223300   \n",
       "2005-03-22  43.209999  43.220001  42.549999  42.650002  42.650002  2609400   \n",
       "2005-03-24  42.509998  42.540001  42.369999  42.389999  42.389999  1466300   \n",
       "2005-04-07  42.770000  42.810001  42.529999  42.570000  42.570000  2853000   \n",
       "2005-04-08  42.480000  42.709999  42.459999  42.689999  42.689999  1002100   \n",
       "\n",
       "           ticker  adjclose_15  true_adjclose_15  \n",
       "2005-02-10    GLD    42.289406         43.380001  \n",
       "2005-02-11    GLD    42.646286         43.470001  \n",
       "2005-02-16    GLD    43.380287         44.200001  \n",
       "2005-02-23    GLD    43.330578         44.310001  \n",
       "2005-03-15    GLD    43.707573         42.630001  \n",
       "2005-03-16    GLD    43.898426         42.570000  \n",
       "2005-03-22    GLD    42.940781         42.900002  \n",
       "2005-03-24    GLD    42.825783         42.400002  \n",
       "2005-04-07    GLD    42.657501         43.000000  \n",
       "2005-04-08    GLD    42.648254         43.349998  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_15</th>\n",
       "      <th>true_adjclose_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>168.660004</td>\n",
       "      <td>169.210007</td>\n",
       "      <td>168.529999</td>\n",
       "      <td>168.929993</td>\n",
       "      <td>168.929993</td>\n",
       "      <td>4881300</td>\n",
       "      <td>GLD</td>\n",
       "      <td>169.370728</td>\n",
       "      <td>174.179993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-08</th>\n",
       "      <td>170.429993</td>\n",
       "      <td>170.699997</td>\n",
       "      <td>170.059998</td>\n",
       "      <td>170.449997</td>\n",
       "      <td>170.449997</td>\n",
       "      <td>4966100</td>\n",
       "      <td>GLD</td>\n",
       "      <td>166.551010</td>\n",
       "      <td>165.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18</th>\n",
       "      <td>173.960007</td>\n",
       "      <td>174.360001</td>\n",
       "      <td>173.529999</td>\n",
       "      <td>173.940002</td>\n",
       "      <td>173.940002</td>\n",
       "      <td>6252000</td>\n",
       "      <td>GLD</td>\n",
       "      <td>168.690765</td>\n",
       "      <td>166.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-23</th>\n",
       "      <td>167.279999</td>\n",
       "      <td>167.600006</td>\n",
       "      <td>166.529999</td>\n",
       "      <td>167.279999</td>\n",
       "      <td>167.279999</td>\n",
       "      <td>8047800</td>\n",
       "      <td>GLD</td>\n",
       "      <td>167.034805</td>\n",
       "      <td>166.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-15</th>\n",
       "      <td>165.270004</td>\n",
       "      <td>166.399994</td>\n",
       "      <td>163.800003</td>\n",
       "      <td>166.149994</td>\n",
       "      <td>166.149994</td>\n",
       "      <td>14231200</td>\n",
       "      <td>GLD</td>\n",
       "      <td>167.038498</td>\n",
       "      <td>166.990005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-20</th>\n",
       "      <td>167.880005</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>167.059998</td>\n",
       "      <td>167.089996</td>\n",
       "      <td>167.089996</td>\n",
       "      <td>6973000</td>\n",
       "      <td>GLD</td>\n",
       "      <td>167.573715</td>\n",
       "      <td>170.289993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-22</th>\n",
       "      <td>167.580002</td>\n",
       "      <td>168.639999</td>\n",
       "      <td>167.110001</td>\n",
       "      <td>168.589996</td>\n",
       "      <td>168.589996</td>\n",
       "      <td>4672900</td>\n",
       "      <td>GLD</td>\n",
       "      <td>168.096985</td>\n",
       "      <td>170.160004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>169.330002</td>\n",
       "      <td>169.649994</td>\n",
       "      <td>168.619995</td>\n",
       "      <td>168.639999</td>\n",
       "      <td>168.639999</td>\n",
       "      <td>4541900</td>\n",
       "      <td>GLD</td>\n",
       "      <td>168.209961</td>\n",
       "      <td>172.080002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>170.619995</td>\n",
       "      <td>170.929993</td>\n",
       "      <td>168.899994</td>\n",
       "      <td>169.059998</td>\n",
       "      <td>169.059998</td>\n",
       "      <td>8715600</td>\n",
       "      <td>GLD</td>\n",
       "      <td>168.291061</td>\n",
       "      <td>167.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>167.160004</td>\n",
       "      <td>167.750000</td>\n",
       "      <td>166.860001</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>10902700</td>\n",
       "      <td>GLD</td>\n",
       "      <td>167.796967</td>\n",
       "      <td>167.100006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "2021-10-25  168.660004  169.210007  168.529999  168.929993  168.929993   \n",
       "2021-11-08  170.429993  170.699997  170.059998  170.449997  170.449997   \n",
       "2021-11-18  173.960007  174.360001  173.529999  173.940002  173.940002   \n",
       "2021-11-23  167.279999  167.600006  166.529999  167.279999  167.279999   \n",
       "2021-12-15  165.270004  166.399994  163.800003  166.149994  166.149994   \n",
       "2021-12-20  167.880005  168.000000  167.059998  167.089996  167.089996   \n",
       "2021-12-22  167.580002  168.639999  167.110001  168.589996  168.589996   \n",
       "2021-12-28  169.330002  169.649994  168.619995  168.639999  168.639999   \n",
       "2022-01-05  170.619995  170.929993  168.899994  169.059998  169.059998   \n",
       "2022-01-06  167.160004  167.750000  166.860001  166.990005  166.990005   \n",
       "\n",
       "              volume ticker  adjclose_15  true_adjclose_15  \n",
       "2021-10-25   4881300    GLD   169.370728        174.179993  \n",
       "2021-11-08   4966100    GLD   166.551010        165.500000  \n",
       "2021-11-18   6252000    GLD   168.690765        166.580002  \n",
       "2021-11-23   8047800    GLD   167.034805        166.149994  \n",
       "2021-12-15  14231200    GLD   167.038498        166.990005  \n",
       "2021-12-20   6973000    GLD   167.573715        170.289993  \n",
       "2021-12-22   4672900    GLD   168.096985        170.160004  \n",
       "2021-12-28   4541900    GLD   168.209961        172.080002  \n",
       "2022-01-05   8715600    GLD   168.291061        167.600006  \n",
       "2022-01-06  10902700    GLD   167.796967        167.100006  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:  3.3498163071939566\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# calculate root mean squared error\n",
    "rmse = math.sqrt(mean_squared_error(final_df[\"adjclose_15\"], final_df[\"true_adjclose_15\"]))\n",
    "\n",
    "print('rmse: ',rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
